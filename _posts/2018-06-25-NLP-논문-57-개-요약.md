---
layout: post
comments: true
title: 논문 요약&#58; 17년도 NLP 논문 57개 짧게 요약
key: 201806251
tags:
  - NLP
  - 논문
---

> Marek Rei의 블로그 포스트(http://www.marekrei.com/blog/paper-summaries/) 옮김

57개의 논문과 요약이라 하기에도 좀 짧은 각 3-4문장의 노트
<!--more-->
<br>
<br>

1. A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task

Danqi Chen, Jason Bolton, Christopher D. Manning. Stanford. ACL 2016.

[논문 링크](https://arxiv.org/pdf/1606.02858.pdf)

<br>

CNN(뉴스)과 Daily Mail 데이터를 읽고 이해하는 task를 수행할 때 중요 포인트를 담았는지 체크하기 위해 Hermann et al (2015)이 제작한 데이터셋이 있다.
텍스트의 모든 entity가 비워져 있고 올바르게 채워 넣을 수 있는지 확인하는 데이터셋.

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/1.png)

본 논문에서는 100 sample을 뽑아 인간이 직접 수행해 보았고 25% 정도의 question은 인간도 정확히 답하기 어렵다는 것을 보였다.
간단한 attention-based classifier를 이용하여 기존 performance를 상회하는 결과를 만들어 냈다.

<br>

{:start="2"}
2. Word Translation Without Parallel Data

Alexis Conneau, Guillaume Lample, Marc’Aurelio Ranzato, Ludovic Denoyer, Hervé Jégou. Facebook, Le Mans, Sorbonne. ArXiv 2017.

[논문 링크](https://arxiv.org/pdf/1710.04087.pdf)

<br>

parallel corpus없이 각각 언어의 독자적은 corpus만 가지고 변역 학습을 하였다.
각 언어에 서로 다른 embedding이 학습되고, 대척되는 objective(cat<->gatto)의 mapping을 학습한다.
너무 흔하게 등장하는 단어들에는 orthogonality constraint를 준다. 또한, unsupervised stopping(기계번역에서 target word가 그만 생성되는 지점) 방법을 제시하였다.

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/2.png)

<br>

{:start="3"}
3. A Nested Attention Neural Hybrid Model for Grammatical Error Correction

Jianshu Ji, Qinlong Wang, Kristina Toutanova, Yongen Gong, Steven Truong, Jianfeng Gao. ACL 2017.

[논문 링크](http://aclweb.org/anthology/P/P17/P17-1070.pdf)

<br>

Grammatical error를 교정하는 모델, OOV words(out-of-vocabulary)가 character-based RNNs을 통과하여 decoder가 교정된 단어를 생성한다.

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/3.png)

<br>

{:start="4"}
4. On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems

Pei-Hao Su, Milica Gasic, Nikola Mrksic, Lina Rojas-Barahona, Stefan Ultes, David Vandyke, Tsung-Hsien Wen, Steve Young. Cambridge. ACL 2016.

[논문 링크](http://aclweb.org/anthology/P/P16/P16-1230.pdf)

<br>

Cambridge(UK) 구역의 레스토랑 정보를 물어보면 응답해주는 spoken dialogue system을 만들었다. user의 current dialogue에 따라 해당 action과 label을 extract하여 답을 주는데, 확실한 label은 그대로 진행하고
불확실한 label에 대해서는 user에게 다시 물어본다. active learning을 통해 annotation 양을 줄여준다.

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/4.png)

dialogue는 bi-LSTM을 통해 vector로 표현되고 dialogue success는 Gaussian Process로 모델링된다.

<br>

{:start="5"}
5. Vision and Feature Norms: Improving automatic feature norm learning through cross-modal maps

Luana Bulat, Douwe Kiela, Stephen Clark. Cambridge. NAACL 2016.

[논문 링크](http://aclweb.org/anthology/N/N16/N16-1071.pdf)

<br>

task는 feature norm을 예측하는 것이다. input word(ex. banana)를 이용하여 google에서 이미지 10장을 가져오고, 각 이미지마다
ImageNet classifier를 이용하여 feature vector를 뽑아서 각 feature마다 평균을 낸다.
이후, feature norm이 input vector(image-based, distributional, or a combination)의 결과로 train된다.

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/5.png)


<br>

{:start="6"}
6. Adversarial examples in the physical world

Alexey Kurakin, Ian J. Goodfellow, Samy Bengio. Google, OpenAI. ArXiv.

[논문 링크](https://arxiv.org/abs/1607.02533)

<br>

Adversarial example이란, input data를 살짝 가공하여 classfier가 다른 class로 예측하도록 만들어진 datapoint이다.
여기서 input data에 만들어지는 변화는 아주 작아서 인간이 인식하지 못할 정도일 수도 있다.

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/6.png)

본 논문에서는, 인위적으로 만들어 진 변화가 아닌, real world에서 카메라의 설정(화질, 밝기, contrast, noise 등)으로 얼마나 accuracy가 변화하는지 실험하였다.

<br>

{:start="7"}
7. Extracting token-level signals of syntactic processing from fMRI – with an application to POS induction

Joachim Bingel, Maria Barrett, Anders Søgaard. Copenhagen. ACL 2016.

[논문 링크](http://aclweb.org/anthology/P/P16/P16-1071.pdf)

<br>

fMRI feature를 POS tagging과 함께 이용한다.
의미적으로/문법적으로 다른 단어들을 읽을 때(text data는 해리포터) 뇌의 반응을 unsupervised POS-tagger에 word와 같이 사용하여 performance를 높였다.

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/7.png)


<br>

{:start="8"}
8. Joint Extraction of Events and Entities within a Document Context

Bishan Yang, Tom Mitchell. Carnegie Mellon. NAACL 2016.

[논문 링크](http://aclweb.org/anthology/N/N16/N16-1033.pdf)

<br>

kewords, entities, 그리고 events와 entities간 connection, 이렇게 3가지를 추출하는 joint model을 개발하였다.
entity dection은 CRF을 이용하였고, event structure는 probabilistic graphical model을 사용한다.

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/8.png)


<br>

{:start="9"}
9. Candidate re-ranking for SMT-based grammatical error correction

Zheng Yuan, Ted Briscoe, Mariano Felice. Cambridge. BEA Workshop 2016.

[논문 링크](https://www.aclweb.org/anthology/W/W16/W16-0530.pdf)

<br>

ranking SVM을 이요하여 SMT의 prediction을 re-ranking하여 생성되었던 target 문장의 grammar 오류를 정정한다.

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/9.png)


<br>

{:start="10"}
10. Variational Neural Machine Translation

Biao Zhang, Deyi Xiong, Jinsong Su, Hong Duan, Min Zhang. Soochow University, Xiamen University. ArXiv.

[논문 링크](https://arxiv.org/abs/1605.07869)

<br>

Bahdanau et al. (2014)의 NMT model with alignment에, extra variational component를 추가하였다.

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/10.png)

이렇게 하여 추가적으로 번역되는 문장의 의미를 가지는 latent variable z를 추적한다. 먼저 input과 output에 제한되는 z의 posterior probability를 모델링하고,
input에만 제한되는 prior또한 모델링한다. 두개의 distribution은 Kullback-Leibler distance에 의해 최적화되고, testing시에는 prior만 사용된다.

<br>

{:start="11"}
11. Numerically Grounded Language Models for Semantic Error Correction

Georgios P. Spithourakis, Isabelle Augenstein, Sebastian Riedel. UCL. EMNLP 2016.

[논문 링크](https://arxiv.org/abs/1608.04147)

<br>

knowledge base에 제한되며 numerical value를 handling하는 LSTM language model을 만들었다.

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/11.png)

원래 우리는 "25"와 같은 token을 평범한 word embedding에 똑같이 적용하였었으나 float(25)와 같이 표현한다.
그리고 KB(knowledge base)의 모든 정보는 string으로 LSTM으로 모델링되어 main language model을 제한한다.

<br>

{:start="12"}
12. Black Holes and White Rabbits : Metaphor Identification with Visual Features

Ekaterina Shutova, Douwe Kiela, Jean Maillard. Cambridge. NAACL 2016.

[논문 링크](https://www.aclweb.org/anthology/N/N16/N16-1020.pdf)

<br>

“blind alley”, “honest meal” 와 같은 metaphor detection system을 개발하였다.

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/12.png)

기본적으로 word embedding similarity를 이용한다. word2vec의 cosine similarity를 계산하고, phrase 별 similiarity를 계산한다.

이후, word와 phrase에 대해 vector representation을 완성하는데, words Google Image Search의 query로 사용하여
return image를 vector representation에 이용한다. 마지막으로 시스템이 linguistic vector와 visual vector를 이용하여 classify한다.

<br>

{:start="13"}
13. Counter-fitting Word Vectors to Linguistic Constraints

Nikola Mrkšić, Diarmuid Ó Séaghdha, Blaise Thomson, Milica Gašić, Lina Rojas-Barahona, Pei-Hao Su, David Vandyke, Tsung-Hsien Wen, Steve Young. Cambridge, Apple. NAACL 2016.

[논문 링크](http://www.aclweb.org/anthology/N16-1018)

<br>

semantic constraints 하에 word embedding을 조절한다.

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/13.png)

word vector들은 1) known synonyms에 high similarity를 가지고, 2) known antonyms에 low synonyms를 가지고,
3) original space에서의 similarity를 가진다.

<br>

{:start="14"}
14. Bidirectional RNN for Medical Event Detection in Electronic Health Records

Abhyuday N. Jagannatha, Hong Yu. University of Massachusetts. NAACL 2016.

[논문 링크](https://www.aclweb.org/anthology/N/N16/N16-1056.pdf)

<br>

780 electronic health records를 데이터셋으로 이용하여 medical events(drug events, drug dosage, etc)를 labeling한다.

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/14.png)

CRF, LSTM, GRU를 사용하여 실험하였고 전체 문서에 대해 학습된 GRU가 가장 좋은 performance를 냈다.

<br>

{:start="15"}
15. Symmetric Patterns and Coordinations: Fast and Enhanced Representations of Verbs and Adjectives

Roy Schwartz, Roi Reichart, Ari Rappoport. The Hebrew Universit, IIT. NAACL 2016.

[논문 링크](http://www.aclweb.org/anthology/N16-1060)

<br>

word2vec skip-gram embeddings를 학습시킬 때 coordinations를 context로 이용하였다.
coordination을 추출하기 위해 11개의 manual patterns를 적용시켰는데 예를 들어 "boats or planes"라 하면
"boats"는 "planes"의 context가 되고 "planes"는 "boats"의 context가 된다.

<br>

{:start="16"}
16. Comparing Data Sources and Architectures for Deep Visual Representation Learning in Semantics

Douwe Kiela, Anita L. Verő, Stephen Clark. Cambridge. EMNLP 2016.

[논문 링크](https://aclweb.org/anthology/D/D16/D16-1043.pdf)

<br>

image recognition task를 수행하던 architecture들(AlexNet, GoogLeNet, VGGNet)를 여러 데이터셋 하에 비교하였다.

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/16.png)

모두 비슷비슷했는데, VGGNet이 computational cost가 더 적다. ImageNet 데이터가 VGGNet에서 잘 분석되고 ESP Game dataset에서 가장 퍼포먼스가 나빴다.

<br>

{:start="17"}
17. Named Entity Recognition for Novel Types by Transfer Learning

Lizhen Qu, Gabriela Ferraro, Liyuan Zhou, Weiwei Hou, Timothy Baldwin. Melbourne. EMNLP 2016.

[논문 링크](http://aclweb.org/anthology/D16-1087)

<br>

NER에서 source domain의 label set과 target domain의 label이 다른 문제점에 ㄷ해 다룬다.

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/17.png)

먼저 source domain에서 CRF 모델을 학습시킨 후, 모델이 예측한 label들을 LR classifier에서 weights를 생성해 또 다른 CRF model에서 target domain data에 fine-tuned하게 classify된다.

<br>

{:start="18"}
18. Hybrid computing using a neural network with dynamic external memory

Alex Graves, Greg Wayne, Malcolm Reynolds et al. DeepMind. Nature.

[논문 링크](http://www.nature.com/nature/journal/v538/n7626/full/nature20101.html)

<br>

딥마인드에서 만든 Neural Turing Machine architecture라는데 이름만 들으면 무시무사하다...

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/18.png)

Differentiable Neural Computer (DNC) 라고 부른다.
1) attention mechanism을 이용하여 memory로 이용되는 matrix에 접속한다.
2) attention machanism을 이용하여 해당 memory에 information을 저장한다.
3) sequential information을 잘 처리하기 위해 transition matrix가 memory가 row별로 어떻게 modify되는지 추적한다.

bAbI question answering dataset, graph inference task, puzzle of arranging block의 task에서 실험해 보았다고 한다.

미쳤다 딥마인드;

<br>

{:start="19"}
19. A Neural Approach to Automated Essay Scoring

Kaveh Taghipour, Hwee Tou Ng. Singapore. EMNLP 2016.

[논문 링크](https://aclweb.org/anthology/D/D16/D16-1193.pdf)

<br>

essay 점수매기는 neural network structure

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/19.png)

window size 3의 convolutional layer 이후 LSTM에 들어간다. LSTM output은 timestep에 따라 평균을 내고 [0,1] 범위로 scale-down하여 score가 된다.
Kaggle essay scoring dataset에서 quadratic weighted Kappa로 측정되었다고 한다.

<br>

{:start="20"}
20. Globally Coherent Text Generation with Neural Checklist Models

Chloe Kiddon, Luke Zettlemoyer, Yejin Choi. Washington. EMNLP 2016.

[논문 링크](https://aclweb.org/anthology/D/D16/D16-1032.pdf)

<br>



![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/20.png)


<br>

{:start="21"}
21. Automatic Features for Essay Scoring – An Empirical Study

Fei Dong, Yue Zhang. Singapore. EMNLP 2016.

[논문 링크](https://www.aclweb.org/anthology/D/D16/D16-1115.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/21.png)


<br>

{:start="22"}
22. Learning Deep Structure-Preserving Image-Text Embeddings

Liwei Wang, Yin Li, Svetlana Lazebnik. University of Illinois, Georgia Tech. CVPR 2016.

[논문 링크](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Wang_Learning_Deep_Structure-Preserving_CVPR_2016_paper.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/22.png)


<br>

{:start="23"}
23. Understanding deep learning requires rethinking generalization

Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol Vinyals. Google Brain, DeepMind. ICLR 2017.

[논문 링크](https://arxiv.org/pdf/1611.03530.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/23.png)


<br>

{:start="24"}
24. Reinforcement Learning with Unsupervised Auxiliary Tasks

Max Jaderberg, Volodymyr Mnih, Wojciech Marian Czarnecki Tom Schaul, Joel Z Leibo, David Silver & Koray Kavukcuoglu. DeepMind. ICLR 2017.

[논문 링크](https://arxiv.org/abs/1611.05397)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/24.png)


<br>

{:start="25"}
25. Modelling metaphor with attribute-based semantics

Luana Bulat, Stephen Clark, Ekaterina Shutova. Cambridge. EACL 2017.

[논문 링크](http://aclweb.org/anthology/E/E17/E17-2084.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/25.png)


<br>

{:start="26"}
26. Enriching Word Vectors with Subword Information

Piotr Bojanowski, Edouard Grave, Armand Joulin, Tomas Mikolov. Facebook. ArXiv 2016.

[논문 링크](https://arxiv.org/abs/1607.04606)



{:start="27"}
27. Learning to Compose Words into Sentences with Reinforcement Learning

Dani Yogatama, Phil Blunsom, Chris Dyer, Edward Grefenstette, Wang Ling. DeepMind. ICLR 2017.

[논문 링크](https://arxiv.org/abs/1611.09100)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/27.png)


<br>

{:start="28"}
28. Identifying beneficial task relations for multi-task learning in deep neural networks

Joachim Bingel, Anders Søgaard. Copenhagen. EACL 2017.

[논문 링크](http://www.aclweb.org/anthology/E17-2026)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/28.png)


<br>

{:start="29"}
29. Literal and Metaphorical Senses in Compositional Distributional Semantic Models

E. Darío Gutiérrez, Ekaterina Shutova, Tyler Marghetis, Benjamin K. Bergen. UCSD, Cambridge, Bloomington. ACL 2016.

[논문 링크](http://www.aclweb.org/anthology/P16-1018)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/29.png)


<br>

{:start="30"}
30. Data Noising as Smoothing in Neural Network Language Models

Ziang Xie, Sida I. Wang, Jiwei Li, Daniel Levy, Aiming Nie, Daniel Jurafsky, Andrew Y. Ng. Stanford. ICLR 2017.

[논문 링크](https://arxiv.org/abs/1703.02573)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/30.png)


<br>

{:start="31"}
31. Neural Belief Tracker: Data-Driven Dialogue State Tracking

Nikola Mrkšić, Diarmuid Ó Séaghdha, Tsung-Hsien Wen, Blaise Thomson, Steve Young. Cambridge, Apple. ACL 2017.

[논문 링크](http://aclweb.org/anthology/P/P17/P17-1163.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/31.png)


<br>

{:start="32"}
32. Neural Architectures for Fine-grained Entity Type Classification

Sonse Shimaoka, Pontus Stenetorp, Kentaro Inui, Sebastian Riedel. Tohoku, UCL. EACL 2017.

[논문 링크](https://www.aclweb.org/anthology/E17-1119)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/32.png)


<br>

{:start="33"}
33. Recurrent Additive Networks

Kenton Lee, Omer Levy, Luke Zettlemoyer. Washington, Allen Institute. ArXiv 2017.

[논문 링크](https://arxiv.org/abs/1705.07393)



{:start="34"}
34. A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification

Ye Zhang, Byron Wallace. UT Austin. IJCNLP 2017.

[논문 링크](https://www.aclweb.org/anthology/I/I17/I17-1026.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/34.png)


<br>

{:start="35"}
35. On Using Monolingual Corpora in Neural Machine Translation

Caglar Gulcehre, Orhan Firat, Kelvin Xu, Kyunghyun Cho, Loic Barrault, Huei-Chi Lin, Fethi Bougares, Holger Schwenk, Yoshua Bengio. Montreal, METech, Maine. Computer Speech and Language 2016.

[논문 링크](https://arxiv.org/abs/1503.03535)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/35.png)


<br>

{:start="36"}
36. Semi-supervised sequence tagging with bidirectional language models

Matthew E. Peters, Waleed Ammar, Chandra Bhagavatula, Russell Power. Allen Institute. ACL 2017.

[논문 링크](http://aclweb.org/anthology/P/P17/P17-1161.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/36.png)


<br>

{:start="37"}
37. Weakly Supervised Part-of-speech Tagging Using Eye-tracking Data

Maria Barrett, Joachim Bingel, Frank Keller, Anders Søgaard. Copenhagen. ACL 2016.

[논문 링크](https://www.aclweb.org/anthology/P/P16/P16-2094.pdf)



{:start="38"}
38. Massive Exploration of Neural Machine Translation Architectures

Denny Britz, Anna Goldie, Minh-Thang Luong, Quoc Le. Google Brain. EMNLP 2017.

[논문 링크](http://aclweb.org/anthology/D17-1151)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/38.png)


<br>

{:start="39"}
39. Learning to Reason: End-to-End Module Networks for Visual Question Answering

Ronghang Hu, Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Kate Saenko. Berkeley, Facebook, Boston. ICCV 2017.

[논문 링크](https://arxiv.org/pdf/1704.05526.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/39.png)


<br>

{:start="40"}
40. Automatic Annotation and Evaluation of Error Types for Grammatical Error Correction

Christopher Bryant, Mariano Felice, Ted Briscoe. Cambridge. ACL 2017.

[논문 링크](http://aclweb.org/anthology/P/P17/P17-1074.pdf)



{:start="41"}
41. Dynamic Evaluation of Neural Sequence Models

Ben Krause, Emmanuel Kahembwe, Iain Murray, Steve Renals. Edinburgh. ArXiv 2017.

[논문 링크](https://arxiv.org/abs/1709.07432)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/41.png)


<br>


{:start="42"}
42. Unsupervised Machine Translation Using Monolingual Corpora Only

Guillaume Lample, Ludovic Denoyer, Marc’Aurelio Ranzato. Facebook, Sorbonne. ArXiv 2017.

[논문 링크](https://arxiv.org/abs/1711.00043)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/42.png)


<br>

{:start="43"}
43. Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies

Tal Linzen, Emmanuel Dupoux, Yoav Goldberg. ENS, Bar Ilan. TACL 2017.

[논문 링크](http://aclweb.org/anthology/Q/Q16/Q16-1037.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/43.png)


<br>

{:start="44"}
44. Multiple Instance Learning Networks for Fine-Grained Sentiment Analysis

Stefanos Angelidis, Mirella Lapata. Edinburgh. ArXiv 2017.

[논문 링크](https://arxiv.org/pdf/1711.09645.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/44.png)


<br>

{:start="45"}
45. Learning how to Active Learn: A Deep Reinforcement Learning Approach

Meng Fang, Yuan Li, Trevor Cohn. Melbourne. EMNLP 2017.

[논문 링크](http://aclweb.org/anthology/D/D17/D17-1063.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/45.png)


<br>

{:start="46"}
46. On the State of the Art of Evaluation in Neural Language Models

Gábor Melis, Chris Dyer, Phil Blunsom. Deepmind, Oxford. ArXiv 2017.

[논문 링크](https://arxiv.org/pdf/1707.05589.pdf)



{:start="47"}
47. Dynamic Routing Between Capsules

Sara Sabour, Nicholas Frosst, Geoffrey E Hinton. Google Brain. NIPS 2017.

[논문 링크](https://arxiv.org/pdf/1710.09829.pdf)



{:start="48"}
48. Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss

Barbara Plank, Anders Søgaard, Yoav Goldberg. Groningen, Copenhagen, Bar-Ilan. ACL 2016.

[논문 링크](http://aclweb.org/anthology/P/P16/P16-2067.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/48.png)


<br>

{:start="49"}
49. Emergent Translation in Multi-Agent Communication

Jason Lee, Kyunghyun Cho, Jason Weston, Douwe Kiela. Facebook. ArXiv 2017.

[논문 링크](https://arxiv.org/pdf/1710.06922.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/49.png)


<br>

{:start="50"}
50. Efficient softmax approximation for GPUs

Edouard Grave, Armand Joulin, Moustapha Cissé, David Grangier, Hervé Jégou. Facebook. ICML 2017.

[논문 링크](https://arxiv.org/pdf/1609.04309.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/50.png)


<br>


{:start="51"}
51. Semi-supervised Multitask Learning for Sequence Labeling

Marek Rei. Cambridge. ACL 2017.

[논문 링크](http://aclweb.org/anthology/P/P17/P17-1194.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/51.png)


<br>

{:start="52"}
52. Grasping the Finer Point: A Supervised Similarity Network for Metaphor Detection

Marek Rei, Luana Bulat, Douwe Kiela, Ekaterina Shutova. Cambridge, Facebook. EMNLP 2017.

[논문 링크](http://aclweb.org/anthology/D/D17/D17-1162.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/52.png)


<br>

{:start="53"}
53. Neural Sequence-Labelling Models for Grammatical Error Correction

Helen Yannakoudakis, Marek Rei, Øistein E. Andersen, Zheng Yuan. Cambridge. EMNLP 2017.

[논문 링크](http://aclweb.org/anthology/D/D17/D17-1297.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/53.png)


<br>

{:start="54"}
54. Artificial Error Generation with Machine Translation and Syntactic Patterns

Marek Rei, Mariano Felice, Zheng Yuan, Ted Briscoe. Cambridge. BEA 2017.

[논문 링크](http://aclweb.org/anthology/W/W17/W17-5032.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/54.png)


<br>

{:start="55"}
55. Auxiliary Objectives for Neural Error Detection Models

Marek Rei, Helen Yannakoudakis. Cambridge. BEA 2017.

[논문 링크](http://aclweb.org/anthology/W/W17/W17-5004.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/55.png)


<br>

{:start="56"}
56. An Error-Oriented Approach to Word Embedding Pre-Training

Youmna Farag, Marek Rei, Ted Briscoe. Cambridge. BEA 2017.

[논문 링크](http://aclweb.org/anthology/W/W17/W17-5016.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/56.png)


<br>

{:start="57"}
57. Detecting Off-topic Responses to Visual Prompts

Marek Rei. Cambridge. BEA 2017.

[논문 링크](http://aclweb.org/anthology/W/W17/W17-5020.pdf)

<br>


![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/paper-summary/57/57.png)


<br>









































