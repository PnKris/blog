---
comments: true
title: 면접 준비
key: 201904060
picture_frame: shadow
tags:
  - ㅠㅠ
---

면접 문제들을 모아봤는데 Markdown 형식이 code block도 있고 워드보다 익숙해서 여기다 정리하고 다 풀면 지우려 합니다. 코딩 테스트 준비는 [백준](https://www.acmicpc.net/user/q0115643)에서!

<!--more-->

> 당분간 저만 알아볼 수 있을겁니다.

<br>

# DS, ALGO, PL, DB, Network, OS

## DS and ALGO

- Data Structures

**Data Structure**

데이터구조는 정돈된 데이터의 집합으로 특정 방식으로 데이터를 넣고, 꺼낼 수 있게 합니다.

**ADT (Abstract Data Type)**

"Data" + "Operations on the data" => "A Data Type"

Data Type은 해당 프로그래밍 언어가 정의해놓은 Primitive Data Type = Concrete Data Type과 Abstract Data Type으로 나뉜다.

**Array**

인덱스를 이용하여 데이터를 삽입하거나 참조합니다.

create, retrieve, store operation이 있습니다.

인덱스를 안다면 1 step에 데이터를 찾을 수 있지만, 데이터 사이에 삽입을 하려면 먼저 데이터들을 옮겨야 합니다.

**Linked-List**

index 대신 다음 node의 주소를 들고 있게 합니다. 데이터는 선형 탐색으로 찾아야 하지만 삽입과 제거는 O(1)에 가능합니다.

C로 구현한다면 데이터 삽입과 삭제는 Malloc과 free를 반복하며 하게 됩니다.

Singly-Linked, Doubly-Linked

**Stack**

LIFO(Last-In/First-Out) Data Structure

array나 linked-list로 구현합니다.

array로 만드려면 간단히 array 하나와 top-index만 가지고 있으면 됩니다.

**Queue**

FIFO(First-In/First-Out) Data Structure

array를 통한 구현이 stack보다 복잡합니다.

queue의 item들을 한 array에 담고 enqueue, dequeue에 전체 array를 통째로 옮겨가게 만들면 쉽지만 O(n)이 됩니다.
아니면, front와 rear(꼬리) index를 따로 들고 있게 합니다. 이렇게 하면 enqueue/dequeue가 반복될수록 array의 앞이 비고 뒤로 밀리는데,
Circular Array 개념을 이용하여 해결할 수 있습니다.

**Priority Queue**

array를 priority마다 준비하던가, 한 array에 enqueue 할 때 올바른 위치로 들어가도록 합니다.
array나 linked-list를 이용하면 삽입이 O(n)인데, heap을 이용하면 삽입과 삭제가 모두 O(log(n))이 됩니다.


- Time Complexity

**f(n) = O(g(n))**

\|f(n)\| <= C\|g(n)\| 이 항상 성립하게 하는 양의 상수 C가 있다면 이런 big-oh notation이 성립합니다.

"g(n) is an upper bound of f(n)"

**f(n) = Ω(g(n))**

\|f(n)\| >= C\|g(n)\| 이 항상 성립하게 하는 양의 상수 C가 있다면 이런 big-omega notation이 성립합니다.

"g(n) is an lower bound of f(n)"

**f(n) = Θ(g(n))**

f(n) = O(g(n))과 f(n) = Ω(g(n))이 모두 성립하면 이런 big-theta notation이 성립합니다.

"g(n) is both an upper bound and a lower bound of f(n)"

시간 복잡도 분석은 Worst case, Best case, Average case를 따로 다룰 수 있습니다, 예시로 Quick sort가 있죠.


- Tree

Linked-List와 비슷한 구조로 구현됩니다. root node가 존재하며 각 node는 해당 node의 children의 주소들을 가지고 있습니다.

**Binary Tree**

node는 left child와 right child를 가질 수 있습니다. 어디서든 쭉 올라가면 root node가 나옵니다.

**Full Binary Tree**

특정 깊이까지 전부 꽉 차있는 트리입니다.

Full Binary Tree에서 level L (root의 level은 0)의 노드 갯수는 $$2^L$$ 입니다.

**Complete Binary Tree**

최소한 마지막 레벨을 제외하면 Full Binary Tree 구조를 가지며 마지막 레벨의 node는 왼쪽에서부터 채워진 트리입니다.

Complete Binary Tree는 array representation이 있습니다. 좌->우, 상->하로 쭉 채우면 됩니다.

**Pre-order Traversal**

```
현재 노드 작업
Left Child
Right Child
```

**In-order Traversal**

```
Left Child
현재 노드 작업
Right Child
```

**Post-order Traversal**

```
Left Child
현재 노드 작업
Right Child
```

**Binary Search Tree**

왼쪽 subtree의 모든 node의 key는 현재 node의 key보다 작거나 같으며 오른쪽은 큽니다.
skewed tree의 가능성이 있으므로 삽입/삭제/탐색 모두 O(n)이 됩니다.

삭제 매커니즘이 특별한데, 제거해야할 node의 child가 2개로 차있을 경우, 오른쪽 subtree의 최소 key를 가진 node를 제거해야하는 node 자리에 복사하고 원래 자리의 node를 제거합니다.

**Heap**

Heap은 기본적으로 complete binary tree 구조를 가집니다.

MaxHeap: parent는 child에 비하여 크거나 같은 key를 가집니다.

MinHeap: parent는 child에 비하여 작거나 같은 key를 가집니다.

Priority Queue를 만드는데 쓰이므로 삭제는 root node를 대상으로 이루어지며, root node를 맨 오른쪽 leaf node와 바꾼 뒤 삭제, leaf node는 아래로 traverse하며 제자리를 찾게 합니다.

삽입 시에는 마지막 node 자리에 넣고 위로 traverse하며 제자리를 찾게 합니다.

**B-Tree**

skewed tree 문제점을 해결하기 위한 해결방안 중 하나입니다.

node는 둘보다 많은 child node를 가질 수 있으며, 한 node가 여러 element를 가질 수 있습니다.

B-Tree는 M(Minimum)이라는 양수를 가집니다.

1. root는 element를 최소한 1개까지 가질 수 있지만 다른 node들은 최소한 m개의 element를 가져야 합니다.
2. node 내의 element 갯수의 최댓값은 2m입니다.
3. 모든 node의 element는 작은 값부터 정렬된 상태로 array에 담겨있습니다.
4. node가 가지는 subtree는 (node 내의 element 갯수 + 1)개입니다.
5. non-leaf node에서 index i에 위치한 element는 subtree i의 모든 element보다 크고 subtree i+1의 모든 element 값보다 작습니다.
6. 모든 leaf node는 같은 깊이에 있습니다.

탐색: node 내의 element를 선형탐색하여 target을 찾고, 못 찾을 땐 처음으로 만나는 target보다 큰 값의 index가 i면 subtree[i]에 대하여 반복한다.

삽입: 탐색과 같은 방식으로 진행하다 leaf에서 target보다 처음으로 커지는 element 앞으로 삽입한다.
element 갯수가 maximum+1이 되면, 가운데 element를 parent로 보내버립니다. root까지 가버리면 새로운 root를 만듭니다.

삭제: 1) child가 없는데 못찾으면 False, child가 없는데 찾으면 단순 삭제, child가 있는데 찾았다면 직전 subtree의 가장 큰 element와 swap 후 아래에서 삭제합니다.
child가 있는데 root에서 못찾았다면 subtree로 들어가 반복합니다.
이러다 node의 element 갯수가 minimum-1이 된다면 직전 subtree, 직후 subtree 혹은 형제에게서 빌려오거나 합쳐버립니다. 

삽입/삭제/탐색 모두 log(n)


- Graphs

**Graph에는 종류가 많지만 제가 들은 수업에서는 self-loop과 동일한 간선의 반복이 없는 종류만 취급했습니다.**

무한하지 않고 공집합이 아닌 node의 집합 V와 무한하지 않은 간선의 집합 E가 모여 Graph(V, E)를 형성합니다. 

**Free Tree**

root가 없고 connected이며 acyclic한 graph입니다. 

* cycle: a simple path in which the first and the last vertices are the same.

**Undirected Graph**

간선에 방향이 주어져 있지 않습니다.

**Directed Graph**

간선에 방향이 있습니다.

**Complete Graphs**

Undirect에서는 간선의 갯수가 n(n-1)/2 입니다.

Directed에서는 n(n-1)입니다.

**Subgraphs**

V와 E가 상위 그래프에 모두 포함되면 Subgraph라 합니다.

그 외 adjacent, incdent on, adjacent to, adjacent from, in-degree, out-degree

**Adjacency List**

node 갯수 길이의 array의 각 node가 각자 리스트를 이루고 해당 node에서 adjacent한 node가 push_back됩니다.

```
for edge in edges:
    a, b = edge
    # a->b    
    adj[a].push_back(b)
    # Undirected면
    adj[b].push_back(a)
```

out-degree는 찾기 쉽지만 in-degree는 어렵습니다.

**Adjacency Matrix**

고대로 matrix 만드는 겁니다.

```
for edge in edges:
    a, b = edge
    # a->b
    adj[a][b] = 1
    # Undirected면
    adj[b][a] = 1
```

**Depth First Search (DFS)**

아까 나왔던 preorder tree traversal와 같습니다.

```
dfs(v): # 아주 대략적으로...
    visited[v] = True
    for w in v->links:
        if not visited[w]:
            dfs(w)
```

Adjacency List를 이용하면 간선의 갯수만큼 참조가 일어나고, 그 전에는 visit을 위해 node 갯수만큼 참조하므로 $$O(n+e)$$입니다.

Adjacency Matrix를 이용하면 한 node에 인접한 간선을 모두 찾는데 $$O(n)$$이 걸리고 node 갯수만큼 반복하므로 $$O(n^2)$$이 됩니다.

**Breadth First Search (BFS)**

Level order tree search와 같습니다.

```
bfs(v): # 아주 대략적으로...
    q = Queue()
    q.enqueue(v)
    while not q.is_empty():
        v = q.dequeue()
        for w in v->links:
            if not visited[w]:
                bfs(w)
```

시간복잡도는 DFS와 동일하게 Adjacency List에서 $$O(n+e)$$, Adjacency Matrix에서 $$O(n^2)$$입니다.

**Single Source Shortest Path**

하나의 출발점에서 각 정점까지 도달하는데 비용을 계산하여 최단경로를 구하는 것입니다.
기본적으로 Directed Graph 구조를 가지고 설명하며, Undirected일 경우 같은 weight의 directed edge 두 개로 바꾸고 시작합니다.

**Dijkstra Algorithm**

Priority Queue를 이용하여 하나의 정점으로부터 인접한 간선들을 확장해 나가는 방식입니다.
음수 가중치를 갖는 간선이 없어야 합니다.

d[v] 배열을 모두 ∞으로 초기화하고, 시작점의 d[v] 값을 0으로하고 모든 정점을 Priority Queue에 넣습니다.

Queue가 빌 때까지 minimum을 뽑고, 해당 정점에 adjacent한 정점의 d[v]값을 계산하여 업데이트합니다.

```
dijkstra(adjacency_list, v):
    d = [INF for _ in range(len(adjacency_list))]
    d[v] = 0
    q = PriorityQueue()
    for i in range(len(adjacency_list):
        q.enqueue([i, d[i]])
    while not q.is_empty():
        curr, value = q.dequeue()
        for dest, weight in adjacency_list:
            new_v = d[curr] + weight
            if new_v < d[dest]:
                d[dest] = new_v
```

실제로 priority queue를 heap으로 구현하고 visited 등 디테일이 좀 더 있고 path 구하려면 predecessor 배열 만들긴 해야하는데 아무튼 이런 식으로하면 됩니다.

heap에 삽입이 $$O(logE)$$, 그리고 삽입이 정점 갯수에 한해서 이루어지므로 $$O(VlogE)$$, 값 갱신은 간선 갯수에 한해서 이루어지므로 $$O(ElogE)$$,
합쳐서 $$O((E+V)logE)$$, $$V <= E^2$$이므로 $$O((E+V)logV)$$입니다. 피보나치 힙을 사용하면 더 줄일 수 있다고 하네요.

정당성 증명

방문된 정점까지의 거리는 최소 거리임을 증명하면 되는데, 초기에 정점 하나만 있을 때 만족하므로 귀납법 + 귀류법으로 풉니다.

K+1 단계에서 정점 u를 방문하였는데 그 거리가 실제 최소 거리가 아니라고 하면, 다른 정점 u'가 방문되지 않은 채 존재하여 u까지의 실제 최소 거리를 잇는 정점으로 존재한다는 것인데,
그렇게 되면 (중략 w, w'가 등장하는 부분) d[u']가 d[u]보다 작게 되는데 그러면 알고리즘 진행과정에서 u'가 u보다 먼저 방문되었어야 하므로 contradiction이 생기므로 증명 완료됩니다.

**Floyd-Warshall's Algorithm**

얘는 Single Source Shortest Path 뿐만 아니라 All Pairs Shortest Paths를 구해줍니다.

```
floyd_warshall():
    for i in range(E):
        for j in range(E):
            for k in range(E):
                if adj[i][k] > adj[j][i] + adj[i][k]:
                    adj[j][k] = adj[j][i] + adj[i][k]
```
코드만 보셔도 아실 겁니다. $$O(E^3)$$ 입니다. 중요한 점은 가운데 지나가는 정점이 맨 바깥 for문에 위치해야 한다는 것입니다.


**Minimum Cost Spanning Tree**

connected graph G에서 모든 node를 방문하는 cycle이 없는 subgraph를 spnning tree라고 합니다.

weighted undirected graph에서 spanning tree의 모든 간선의 weight 총합이 경우의 수 중 최소라면 해당 tree를
Minimum Cost Spanning Tree라고 부릅니다. (spanning tree with minimum cost)


**Kruskal's Algorithm**

1. edge를 지우고 정점을 독립적인 집합인 forest로 만듭니다.
2. edge를 ascending order로 정렬합니다.
3. cycle을 만들지 않는 가장 작은 edge를 골라 graph에 추가합니다.

```
E(G)를 ascending order로 정렬한다.
T = (V, 공집합) # vertices + no edges
VS =[[v] for v in V]
While num(VS) > 1 and (E(G) is not empty):
    (v, w) = deleteMin(E(G))
    if Find(u) != Find(v):
        replace set(u), set(v) by Union(set(u), set(v))
        add (v, w) to T
```

간선을 정렬하는데에 $$O(ElogE)$$,
그리고 Union과Find가 E번 반복되는데, Union-by-height과 path-compression을 이용하면 Union은 $$O(1)$$ Find는 $$O(log{\star}V)$$가 됩니다.
그렇게 아무튼 $$O(ElogE) + O(Elog{\star}V) = O(ElogE)$$가 됩니다.

크루스칼 알고리즘 정당성 증명

1. 크루스칼로 만들어진 그래프가 Spanning Tree 임은 Acyclic하고 모든 노드를 포함한다는 점으로 간단하게 증명됩니다.
2. Minimum Spanning Tree

귀류법을 통해 크루스칼로 만들어진 트리 T가 MST가 아니라고 합시다. 먼저 알고리즘 시작단계의 공집합에서는 MST를 만족하는데,
어느 순간 크루스칼이 택하는 간선이 아닌 다른 간선 (u, v)가 추가됨으로 MST를 만들게 된다는 의미인데 우리는 간선을 최소 weight 순으로 정렬하고 포함시켰으며
만들어지는 트리가 Spanning Tree 임은 1로 증명되었으므로 모순이 됩니다.

**Prim's Algorithm**

```
prim():
    Q = V - {s}
    For v in V:
        D[v] = INF
        v.predecessor = None
    D[s] = 0
    while not Q.is_empty():
       u = Q.extract_min()
       for v in adj[u]:
           if v in Q and w(u,v) < D[v]:
               D[u] = w(u, v)
               v.predecessor = u    
```

크루스칼의 정점 버전입니다. heap으로 구현하면 $$O((E+V)logV)$$, array를 이용하면 $$O(V^2)$$입니다.

증명

귀류법+귀납법을 사용합니다. K+1번째에 (u, v)를 추가하여 T를 만들면, (u, v)는 실제 MST T'에 포함되지 않아야 합니다.
그러므로 (u, v)를 T'에 추가하면 cyclic한 graph가 됩니다. (u, v)와 T'가 (u, v) 대신 가진 간선을 바꿨을 때
T는 전보다 weight이 더 커지게 되므로 모순입니다. (알고리즘 상)


- Sort Algorithms

**Selection Sort**

```
selection_sort():
    for i in range(n):
        min_idx = i
        for j in range(i + 1, n):
            if a[j] < a[min_idx]:
                min_idx = j
        a[i], a[min_idx] = a[min_idx], a[i]
```

너무 간단합니다. $$O(N^2)$$ 입니다.

**Insertion Sort**

```
insertion_sort():
    for i in range(1, n):
        key = a[i]
        j = i - 1
        while j >= 0 and a[j] > key:
            a[j + 1] = a[j]
            j -= 1
        a[j + 1] = key
```

array 앞의 초기에 1칸짜리 구역을 지정하고 한 칸씩 오른쪽으로 늘리면서 해당 item을 왼쪽 구간의 올바른 위치에 넣는것입니다.
마찬가지로 $$O(N^2)$$ 입니다.

**Bubble Sort**

```
bubble_sort():
    for i in range(n):
        for j in range(n - i - 1):
            if a[j] > a[j + 1]:
                a[j], a[j + 1] = a[j + 1], a[j]
```

뒤에서 i번째 칸을 위해 맨 앞부터 올바른 값을 swap을 반복하며 가져오길 반복합니다.
$$O(N^2)$$ 이고 위 두 정렬보다 성능이 더 나쁩니다.

**Merge Sort**

```
merge_sort(a):
    if n <= 1:
        return a
    mid = n // 2
    g1 = a[:mid]
    g2 = a[mid:]
    merge_sort(g1)
    merge_sort(g2)
    i1 = 0
    i2 = 0
    ia = 0
    while i1 < len(g1) and i2 < len(g2):
        if g1[i1] < g2[i2]:
            a[ia] = g1[i1]
            i1 += 1
            ia += 1
        else:
            a[ia] = g2[i2]
            i2 += 1
            ia += 1
    while i1 < len(g1):
        a[ia] = g1[i1]
        i1 += 1
        ia += 1
    while i2 < len(g2):
        a[ia] = g2[i2]
        i2 += 1
        ia += 1
    return a
```

분할정복으로 분해된 sub-array들을 한 쌍씩 쭉 합쳐주는겁니다.
$$O(NlogN)$$ 이지만 같은 시간복잡도의 다른 정렬들과 다르게 추가적인 memory를 필요로 합니다.

**Quick Sort**

```
quick_sort(a, start_idx, end_idx):
    if len(a) <= 1:
        return a
    else:
        pivot_idx = start_idx + (end_idx - start_idx) // 2
        pivot_val = a[pivot_idx]
        a[pivot_idx], a[end_idx] = a[end_idx], a[pivot_idx]
        store_idx = start_idx
        for i in range(start_idx, end_idx):
            if a[i] < pivot_val:
                a[i], a[store_idx] = a[store_idx], a[i]
                store_idx += 1
        a[store_idx], a[end_idx] = a[end_idx], a[store_idx]
        quick_sort(a, start_idx, pivot_idx - 1)
        quick_sort(a, pivot_idx + 1, end_idx
```

$$O(N)$$의 extra memory를 허용하게 하면 더 쉽게할 수 있지만 위처럼 만들면 extra memory는 starck frame의 $$O(logN)$$ 만 필요합니다.

평균적으로 $$O(NlogN)$$ 의 시간복잡도를 가지지만, 최악의 경우 $$N^2$$ 의 시간복잡도를 가집니다.

시간복잡도에 대한 증명은 [여기](https://www.khanacademy.org/computing/computer-science/algorithms/quick-sort/a/analysis-of-quicksort)를 참고하세요.
근데 교수님 수업에서 적분까지 해가면서 strict하게 증명했던 것 같은데 필기가 남아있지 않네요... 나중에 그때 그 내용 어디서 찾으면 추가할게요.

**Heap Sort**

```
heapify(a, idx, heap_size):
    largest = idx
    left_idx, right_idx = 2 * idx + 1, 2 * idx + 2
    if left_idx < heap_size and a[left_idx] > a[largest]:
        largest = left_idx
    if right_idx < heap_size and a[right_idx] > a[largest]:
        largest = right_idx
    if largest != idx:
        a[largest], a[idx] = a[idx], a[largest]
        heapify(a, largest, heap_size)


heapsort(a):
    n = len(a)
    for i in range((n - 1) // 2, -1, -1):
        heapify(a, i, n)
    for i in range(n - 1, 0, -1):
        a[0], a[i] = a[i], a[0]
        heapify(a, 0, i)
```

이건 코드를 좀 열심히 봐야 이해가 가더군요. 일단 `heapify()` 는 heap을 array로 표현했을 때 idx 위치에 있는 node의
left child, right child와 비교해서 더 셋 중 가장 큰 node를 parent 자리에 위치시키는 겁니다. 이걸 array의 뒤에서부터 해주면 아래에서 자리가 올바르지 않은 node 들이 쭉 올라와서 제자리를 찾으며 정렬이 됩니다.
그리고 두 번째 for문에서는 정렬된 heap에서 max 값인 root를 반복적으로 추출해서 array의 뒤에 위치시키는 겁니다.

complete binary tree에서 left child가 `2*idx+1`, right child가 `2*idx+2`를 index로 가지는 것은 귀납법으로 증명 가능하며,
heapify를 `(n-1)//2`부터 하는 이유는 해당 node가 바로 child를 가질 수 있는 마지막 node이기 때문입니다.


**Topological Sort**

Directed Graph에서 정점들의 선행 순서를 위배하지 않으면서 모든 정점을 나열하는 알고리즘입니다.
Scheduler처럼 작업의 순서가 정해져 있을 때 각각의 작업이 완료되어야 끝나는 문제에 주로 쓰입니다.

```
topological_sort():
    q = Queue()
    for i in range(n):
        if in_degree[n] == 0: 
	    q.enqueue(i)
    for i in range(n):
        if q.is_empty():
            error
        x = q.dequeue()
        answer[i] = x
        for j in adj[x]:
            in_degree[j] -= 1
            if in_degree[j] == 0:
                q.enqueue(j)
```

BFS랑 비슷한데, inDegree를 이용하여 enqueue 합니다. 시간복잡도는 $$O(V+E)$$ 입니다.


**Hashing**

Hashing이란 Hash Function을 이용해 item의 index를 item의 key를 이용해 결정하는 것입니다.

**Collision**

간단하게 array length로 나눠 나머지를 index로 이용하는 방법이 있으며
서로 다른 item이 같은 위치로 배정되는 collision이 일어날 수 있습니다.


**Linear Probing**

collision이 일어난다면 empty spot을 찾을 때까지 선형 이동하여 해당 index로 이동시킵니다.

**Search**

hash function을 통해 index를 찾고 해당 key와 동일한 지 이동해가며 찾습니다.

**Delete**

삭제를 할 때에는 해당 index를 빈 공간으로 만들지만 marking하여 원래 item이 있던 곳임을 표시합니다.

**Double Hashing**

hash function 두 개를 사용해서 collision이 일어나면 hash2로 다음 spot을 찾습니다.

**Chained Hashing**

collision이 일어나도 해당 index에서 linked-list를 형성하며 위치시킵니다.

삽입/삭제/탑색의 시간복잡도가 사실 $$O(1)$$ 은 아닌데 그렇다고 봐도 무방합니다...

**Dynamic Array**

처음엔 작은 길이의 array를 할당하여 사용하고, 해당 사이즈를 넘어가는 삽입이 일어나면 길이를 두 배로 늘린 array를 할당하여 item을 다 옮겨주길 반복합니다.

amortized analysis를 통해 놀랍게도 삽입의 시간복잡도가 $$(nO(1) + O(n))/(n+1) = O(1)$$ 이 됩니다.

**String Matching**

주어진 긴 문자열(길이 m)에서 특정 문자열(길이 n)의 등장 위치를 찾는 알고리즘들입니다.

**Brute Force Algorithm**

모든 상황을 다 검색한다는 의미로 더 크게 쓰이기도 하지만 string matching에서는 앞에서부터 차례대로 검색하는 것입니다.

```
bruteforce():
    for i in range(len(text) - len(pattern) + 1):
        j = 0
        while j < len(pattern) and pattern[j] == text[i + j]:
            j += 1
        if j == len(pattern):
            print(i)
```

시간복잡도는 $$O((n - m + 1)m)$$ 인데 보통 $$n >> m$$ 인 상황이 많으며 그럴 때는 $$O(nm)$$ 입니다.

**Rabin-Karp Algorithm**

Hashing을 이용한 알고리즘입니다.

Rabin Fingerprint라는 hash function을 사용합니다.
alphabet의 길이를 d 라고 하고, pattern을 d-항식으로 두고 갑을 계산합니다.
그리고 Text의 subword에 같은 방법으로 값을 계산하여 비교하는 것입니다.

하지만 이렇게 하면 hash값이 너무 커질 수 있으니 적당한 prime number를 사용해 modular 값을 이용합니다.
그리고 False-Positive를 피하기 위해 해시값이 같을 때 문자열을 직접 비교하고 결과에 추가합니다.

```
rabin_karp():
    h = hash(pattern)
    for i in range(len(text) - len(pattern) + 1):
        if h == hash(text[i:i + len(pattern)]):
            j = 0
            while j < len(pattern) and pattern[j] == text[i + j]:
                j += 1
            if j == len(pattern):
                print(i)
```

이렇게 하면$$O(nm)$$ 입니다만, [Horner's scheme](https://en.wikipedia.org/wiki/Horner%27s_method)을 사용하면 hash값이 한 step 전의 hash값으로 부터 $$O(1)$$에 계산하고,
hit의 경우가 엄청 큰 경우가 아니라면 $$O(n + m)$$ 에 가까워집니다.


**Boyer-Moore Algorithm**

브루트포스처럼 왼쪽에서 오른쪽을 패턴을 이동시키지만 문자 일치 검사는 패턴의 오른쪽부터 합니다.

이 때 3가지의 Bad Character Heuristic을 가집니다.

1. text의 character가 pattern 내에 없는 경우 pattern을 그 character 너머로 이동시킵니다.
2. text의 character가 pattern 내에 있을 경우 pattern 안의 가장 오른쪽의 character와 해당 character를 대치하도록 이동시킵니다.
3. 아니면 한칸이동합니다.

이렇게 해도 브루트포스와 같은 $$O(nm)$$ 을 가지지만 상대적으로 좋은 heuristic이기 때문에 속도가 더 빠르다고 볼 수 있습니다.

뿐만 아니라 Good Suffix Heuristic도 사용하는데, Pattern 내부에서 suffix가 prefix로 등장할 경우,
매칭이 되다가 miss가 나왔을 시 1칸만 움직이는 것이 아니라 prefix를 suffix가 매칭되던 위치로 이동시킬 수 있습니다. 이와 같은 경우를 고려하기 위해
Text를 훑기 전, Pattern의 miss가 나는 위치에 따라 몇 칸을 이동시켜야하는지 미리 계산해두고 사용하는 것입니다.

두 Heuristic을 같이 사용하므로 둘 모두 고려하여 최대 이동거리를 사용합니다.


**Edit Distance**

"LewenStein distance", 주어진 문자열 u, v가 얼마나 다른지 파악하는 것입니다. delete, insert, replace 3가지 operation을 기준으로  몇 번의 oepration을
통해 u를 v로 변환시키는지 d(u, v)로 표현합니다. rule은 여기 옮기지 않겠지만 dynamic programming으로 해결합니다.


**Trie**

Set of Strings을 위한 Data Structure 입니다. 

alphabet의 길이를 d라고 할 때, d-ary tree 구조를 가집니다.

edge에 character가 label되었다고보고, 모든 정점은 해당 정점까지 path의 string을 의미합니다.

구현 방식으로 array를 이용하여 d 길이의 array가 각 vertex를 의미하게 만드는 방법과
linked list를 이용하는 방법이 있습니다.

공간복잡도는 string의 종류를 m이라 할 때 array를 이용하면 $$O(md)$$, linked-list를 이용하면 $$O(m)$$ 입니다.

탐색/삽입/삭제의 시간복잡도는 linked-list의 경우 outdegree를 전부 확인해야하므로 $$O(md)$$, array는 $$O(m)$$이 됩니다.

Linked-list의 경우 edge에 길이가 1 이상인 string을 부여하여(compress paths) 효과적인 구조로 만들 수 있습니다.


**Suffix Tree**

Trie와 비슷해보이지만 string(+ 끝을 뜻하는 "$")의 모든 suffix의 집합을 이용하여 만든 tree입니다.
edge에는 string, node에는 index를 표시합니다. construct 시간복잡도와 공간복잡도는 $$O(n^2)$$ 입니다.

String Matching에 사용되는 경우 pattern(edge 중간에 끊길 수도 있습니다)을 찾고 해당 path에서 나오는 모든 leaf node의 index에 해당 pattern이 존재합니다.

시간복잡도는 $$O(n + m)$$ 입니다.


- Dynamic programming



- External sorting



## PL

- Tail recursion and fibonacci programming



- Call by value/address/reference/name/assignment



- Garbage collection



- Lambda algebra



- Type system and type checking, strong/weak type, dynamic/static type checking



- Compiler, interpreter



## DB

- Indexing



- Why using B+ tree?



- basic SQL concepts and query skills



## Network

- How internet works?



- Process of google.com shows in our browser



- tcp stack



- http, https and ssl



- Traditionally, why has it been better to serve site assets from multiple domains?



- Do your best to describe the process from the time you type in a website's URL to it finishing loading on your screen.



- What are the differences between Long-Polling, Websockets and Server-Sent Events?



- What are HTTP methods? List all HTTP methods that you know, and explain them.



- What is domain pre-fetching and how does it help with performance?



- What are HTTP methods? List all HTTP methods that you know, and explain them.



- Do your best to describe the process from the time you type in a website's URL to it finishing loading on your screen.



- What are the differences between Long-Polling, Websockets and Server-Sent Events?



- What is domain pre-fetching and how does it help with performance?



## System and OS

- Queue, heap, stack, data region of memory



- Difference between out of memory and stack overflow



- Context switching



- VM, page, swap



- Semaphore



- Thread, process



- Multithread, concurrent programming



- Difference between L1 and L2 cache



- deadlock, case and solution



- Other OS basics



# Languages

## OOP overall

- OOP basic



- class



- Inheritance, Multiple In



- Override, overload



- Polymorphism



- Multiple inheritance



## Python



- OOP of Python, class, object, inheritance



- `Constructor`, `__self__`



- How hash table is implemented in Python



- Can class be used as a key of dictionary



- dictionary, mutable, immutable



- Special methods and dunder



- Difference between method and function



- Is `len()` is function? or method?



- Decorator



- Generator, iterator and their difference



- Abstract class



- Type casting



## HTML



- What does a `doctype` do?



- How do you serve a page with content in multiple languages?



- What kind of things must you be wary of when design or developing for multilingual sites?



- What are `data-` attributes good for?



- Consider HTML5 as an open web platform. What are the building blocks of HTML5?



- Describe the difference between a `cookie`, `sessionStorage` and `localStorage`.



- Describe the difference between `<script>`, `<script async>` and `<script defer>`.



- Why is it generally a good idea to position CSS `<link>`s between `<head></head>` and JS `<script>`s just before `</body>`? Do you know any exceptions?



- What is progressive rendering?



- Why you would use a `srcset` attribute in an image tag? Explain the process the browser uses when evaluating the content of this attribute.



- Have you used different HTML templating languages before?



## CSS



- What is CSS selector specificity and how does it work?



- What's the difference between "resetting" and "normalizing" CSS? Which would you choose, and why?



- Describe Floats and how they work.



- Describe z-index and how stacking context is formed.



- Describe BFC (Block Formatting Context) and how it works.



- What are the various clearing techniques and which is appropriate for what context?



- How would you approach fixing browser-specific styling issues?



- How do you serve your pages for feature-constrained browsers?
  
  -  What techniques/processes do you use?



- What are the different ways to visually hide content (and make it available only for screen readers)?



- Have you ever used a grid system, and if so, what do you prefer?



- Have you used or implemented media queries or mobile specific layouts/CSS?



- Are you familiar with styling SVG?



- Can you give an example of an `@media` property other than `screen`?



- What are some of the "gotchas" for writing efficient CSS?



- What are the advantages/disadvantages of using CSS preprocessors?
  
  - Describe what you like and dislike about the CSS preprocessors you have used.



- How would you implement a web design comp that uses non-standard fonts?



- Explain how a browser determines what elements match a CSS selector.



- Describe pseudo-elements and discuss what they are used for.



- Explain your understanding of the box model and how you would tell the browser in CSS to render your layout in different box models.



- What does `* { box-sizing: border-box; }` do? What are its advantages?



- What is the CSS `display` property and can you give a few examples of its use?



- What's the difference between inline and inline-block?



- What's the difference between the "nth-of-type()" and "nth-child()" selectors?



- What's the difference between a relative, fixed, absolute and statically positioned element?



- What existing CSS frameworks have you used locally, or in production? How would you change/improve them?



- Have you played around with the new CSS Flexbox or Grid specs?



- Can you explain the difference between coding a web site to be responsive versus using a mobile-first strategy?



- Have you ever worked with retina graphics? If so, when and what techniques did you use?



- Is there any reason you'd want to use `translate()` instead of absolute positioning, or vice-versa? And why?



## Javascript

- Explain event delegation.



- Explain how `this` works in JavaScript.



- Can you give an example of one of the ways that working with `this` has changed in ES6?



- Explain how prototypal inheritance works.



- What's the difference between a variable that is: `null`, `undefined` or `undeclared`?



- How would you go about checking for any of these states?



- What is a closure, and how/why would you use one?



- What language constructions do you use for iterating over object properties and array items?



- Can you describe the main difference between the `Array.forEach()` loop and `Array.map()` methods and why you would pick one versus the other?



- What's a typical use case for anonymous functions?



- What's the difference between host objects and native objects?



- Explain the difference between: `function Person(){}`, `var person = Person()`, and `var person = new Person()`?



- Explain the differences on the usage of `foo` between `function foo() {}` and `var foo = function() {}`



- Can you explain what `Function.call` and `Function.apply` do? What's the notable difference between the two?



- Explain `Function.prototype.bind`.



- What's the difference between feature detection, feature inference, and using the UA string?



- Explain "hoisting".



- Describe event bubbling.



- Describe event capturing.



- What's the difference between an "attribute" and a "property"?



- What are the pros and cons of extending built-in JavaScript objects?



- What is the difference between `==` and `===`?



- Explain the same-origin policy with regards to JavaScript.



- Why is it called a Ternary operator, what does the word "Ternary" indicate?



- What is strict mode? What are some of the advantages/disadvantages of using it?



- What are some of the advantages/disadvantages of writing JavaScript code in a language that compiles to JavaScript?



- What tools and techniques do you use debugging JavaScript code?



- Explain the difference between mutable and immutable objects.



- What is an example of an immutable object in JavaScript?



- What are the pros and cons of immutability?



- How can you achieve immutability in your own code?



- Explain the difference between synchronous and asynchronous functions.



- What is event loop?



- What is the difference between call stack and task queue?



- What are the differences between variables created using `let`, `var` or `const`?



- What are the differences between **ES6** class and **ES5** function constructors?



- Can you offer a use case for the new arrow `=>` function syntax? How does this new syntax differ from other functions?



- What advantage is there for using the arrow syntax for a method in a constructor?



- What is the definition of a higher-order function?



- Can you give an example for destructuring an object or an array?



- Can you give an example of generating a string with ES6 Template Literals?



- Can you give an example of a curry function and why this syntax offers an advantage?



- What are the benefits of using `spread syntax` and how is it different from `rest syntax`?



- How can you share code between files?



- Why you might want to create static class members?

## Coding questions

- Make this work:

  - `duplicate([1,2,3,4,5]); // [1,2,3,4,5,1,2,3,4,5]`


- Create a for loop that iterates up to `100` while outputting **"fizz"** at multiples of `3`, **"buzz"** at multiples of `5` and **"fizzbuzz"** at multiples of `3` and `5`



- What is the value of `foo`?

```javascript
var foo = 10 + '20';
```


- What will be the output of the code below?

```javascript
console.log(0.1 + 0.2 == 0.3);
```


- How would you make this work?

```javascript
add(2, 5); // 7
add(2)(5); // 7
```


- What value is returned from the following statement?

```javascript
"i'm a lasagna hog".split("").reverse().join("");
```


- What is the value of `window.foo`?

```javascript
( window.foo || ( window.foo = "bar" ) );
```


- What is the outcome of the two alerts below?

```javascript
var foo = "Hello";
(function() {
  var bar = " World";
  alert(foo + bar);
})();
alert(foo + bar);
```


- What is the value of `foo.length`?

```javascript
var foo = [];
foo.push(1);
foo.push(2);
```


- What is the value of `foo.x`?

```javascript
var foo = {n: 1};
var bar = foo;
foo.x = foo = {n: 2};
```



- What does the following code print?

```javascript
console.log('one');
setTimeout(function() {
  console.log('two');
}, 0);
Promise.resolve().then(function() {
  console.log('three');
})
console.log('four');
```


- What is the difference between these four promises?

```javascript
doSomething().then(function () {
  return doSomethingElse();
});

doSomething().then(function () {
  doSomethingElse();
});

doSomething().then(doSomethingElse());

doSomething().then(doSomethingElse);
```



# ETC


- A-star Algorithm


- Django: Thread handling for Django request



- ML data preprocessing methods



- Basic ML theory



- Basic statistics



# 출처

- [h5bp's Github](https://github.com/h5bp/Front-end-Developer-Interview-Questions)

- [keon1.me](https://keon1.me/dev/2019/01/05/interview.html)

