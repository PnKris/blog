---
comments: true
title: 면접 준비 겸 학부 수업 총정리
key: 201904060
picture_frame: shadow
tags:
  - ㅠㅠ
---

면접 문제들을 모아봤는데 Markdown 형식이 code block도 있고 워드보다 익숙해서 여기다 정리하고 다 풀면 지우려 합니다. 코딩 테스트 준비는 [백준](https://www.acmicpc.net/user/q0115643)에서!

<!--more-->

> 당분간 저만 알아볼 수 있을겁니다.

<br>

# DS, ALGO, PL, Network, OS

## DS and ALGO

`Data Structures`{:.info}

**Data Structure**

데이터구조는 정돈된 데이터의 집합으로 특정 방식으로 데이터를 넣고, 꺼낼 수 있게 합니다.

**ADT (Abstract Data Type)**

"Data" + "Operations on the data" => "A Data Type"

Data Type은 해당 프로그래밍 언어가 정의해놓은 Primitive Data Type = Concrete Data Type과 Abstract Data Type으로 나뉜다.

**Array**

인덱스를 이용하여 데이터를 삽입하거나 참조합니다.

create, retrieve, store operation이 있습니다.

인덱스를 안다면 1 step에 데이터를 찾을 수 있지만, 데이터 사이에 삽입을 하려면 먼저 데이터들을 옮겨야 합니다.

**Linked-List**

index 대신 다음 node의 주소를 들고 있게 합니다. 데이터는 선형 탐색으로 찾아야 하지만 삽입과 제거는 O(1)에 가능합니다.

C로 구현한다면 데이터 삽입과 삭제는 Malloc과 free를 반복하며 하게 됩니다.

Singly-Linked, Doubly-Linked

**Stack**

LIFO(Last-In/First-Out) Data Structure

array나 linked-list로 구현합니다.

array로 만드려면 간단히 array 하나와 top-index만 가지고 있으면 됩니다.

**Queue**

FIFO(First-In/First-Out) Data Structure

array를 통한 구현이 stack보다 복잡합니다.

queue의 item들을 한 array에 담고 enqueue, dequeue에 전체 array를 통째로 옮겨가게 만들면 쉽지만 O(n)이 됩니다.
아니면, front와 rear(꼬리) index를 따로 들고 있게 합니다. 이렇게 하면 enqueue/dequeue가 반복될수록 array의 앞이 비고 뒤로 밀리는데,
Circular Array 개념을 이용하여 해결할 수 있습니다.

**Priority Queue**

array를 priority마다 준비하던가, 한 array에 enqueue 할 때 올바른 위치로 들어가도록 합니다.
array나 linked-list를 이용하면 삽입이 O(n)인데, heap을 이용하면 삽입과 삭제가 모두 O(log(n))이 됩니다.

`Time Complexity`{:.info}

**f(n) = O(g(n))**

\|f(n)\| <= C\|g(n)\| 이 항상 성립하게 하는 양의 상수 C가 있다면 이런 big-oh notation이 성립합니다.

"g(n) is an upper bound of f(n)"

**f(n) = Ω(g(n))**

\|f(n)\| >= C\|g(n)\| 이 항상 성립하게 하는 양의 상수 C가 있다면 이런 big-omega notation이 성립합니다.

"g(n) is an lower bound of f(n)"

**f(n) = Θ(g(n))**

f(n) = O(g(n))과 f(n) = Ω(g(n))이 모두 성립하면 이런 big-theta notation이 성립합니다.

"g(n) is both an upper bound and a lower bound of f(n)"

시간 복잡도 분석은 Worst case, Best case, Average case를 따로 다룰 수 있습니다, 예시로 Quick sort가 있죠.


`Tree`{:.info}

Linked-List와 비슷한 구조로 구현됩니다. root node가 존재하며 각 node는 해당 node의 children의 주소들을 가지고 있습니다.

**Binary Tree**

node는 left child와 right child를 가질 수 있습니다. 어디서든 쭉 올라가면 root node가 나옵니다.

**Full Binary Tree**

특정 깊이까지 전부 꽉 차있는 트리입니다.

Full Binary Tree에서 level L (root의 level은 0)의 노드 갯수는 $$2^L$$ 입니다.

**Complete Binary Tree**

최소한 마지막 레벨을 제외하면 Full Binary Tree 구조를 가지며 마지막 레벨의 node는 왼쪽에서부터 채워진 트리입니다.

Complete Binary Tree는 array representation이 있습니다. 좌->우, 상->하로 쭉 채우면 됩니다.

**Pre-order Traversal**

```
현재 노드 작업
Left Child
Right Child
```

**In-order Traversal**

```
Left Child
현재 노드 작업
Right Child
```

**Post-order Traversal**

```
Left Child
현재 노드 작업
Right Child
```

**Binary Search Tree**

왼쪽 subtree의 모든 node의 key는 현재 node의 key보다 작거나 같으며 오른쪽은 큽니다.
skewed tree의 가능성이 있으므로 삽입/삭제/탐색 모두 O(n)이 됩니다.

삭제 매커니즘이 특별한데, 제거해야할 node의 child가 2개로 차있을 경우, 오른쪽 subtree의 최소 key를 가진 node를 제거해야하는 node 자리에 복사하고 원래 자리의 node를 제거합니다.

**Heap**

Heap은 기본적으로 complete binary tree 구조를 가집니다.

MaxHeap: parent는 child에 비하여 크거나 같은 key를 가집니다.

MinHeap: parent는 child에 비하여 작거나 같은 key를 가집니다.

Priority Queue를 만드는데 쓰이므로 삭제는 root node를 대상으로 이루어지며, root node를 맨 오른쪽 leaf node와 바꾼 뒤 삭제, leaf node는 아래로 traverse하며 제자리를 찾게 합니다.

삽입 시에는 마지막 node 자리에 넣고 위로 traverse하며 제자리를 찾게 합니다.

**B-Tree**

skewed tree 문제점을 해결하기 위한 해결방안 중 하나입니다.

node는 둘보다 많은 child node를 가질 수 있으며, 한 node가 여러 element를 가질 수 있습니다.

B-Tree는 M(Minimum)이라는 양수를 가집니다.

1. root는 element를 최소한 1개까지 가질 수 있지만 다른 node들은 최소한 m개의 element를 가져야 합니다.
2. node 내의 element 갯수의 최댓값은 2m입니다.
3. 모든 node의 element는 작은 값부터 정렬된 상태로 array에 담겨있습니다.
4. node가 가지는 subtree는 (node 내의 element 갯수 + 1)개입니다.
5. non-leaf node에서 index i에 위치한 element는 subtree i의 모든 element보다 크고 subtree i+1의 모든 element 값보다 작습니다.
6. 모든 leaf node는 같은 깊이에 있습니다.

탐색: node 내의 element를 선형탐색하여 target을 찾고, 못 찾을 땐 처음으로 만나는 target보다 큰 값의 index가 i면 subtree[i]에 대하여 반복한다.

삽입: 탐색과 같은 방식으로 진행하다 leaf에서 target보다 처음으로 커지는 element 앞으로 삽입한다.
element 갯수가 maximum+1이 되면, 가운데 element를 parent로 보내버립니다. root까지 가버리면 새로운 root를 만듭니다.

삭제: 1) child가 없는데 못찾으면 False, child가 없는데 찾으면 단순 삭제, child가 있는데 찾았다면 직전 subtree의 가장 큰 element와 swap 후 아래에서 삭제합니다.
child가 있는데 root에서 못찾았다면 subtree로 들어가 반복합니다.
이러다 node의 element 갯수가 minimum-1이 된다면 직전 subtree, 직후 subtree 혹은 형제에게서 빌려오거나 합쳐버립니다. 

삽입/삭제/탐색 모두 log(n)

`Graphs`{:.info}

**Graph에는 종류가 많지만 제가 들은 수업에서는 self-loop과 동일한 간선의 반복이 없는 종류만 취급했습니다.**

무한하지 않고 공집합이 아닌 node의 집합 V와 무한하지 않은 간선의 집합 E가 모여 Graph(V, E)를 형성합니다. 

**Free Tree**

root가 없고 connected이며 acyclic한 graph입니다. 

* cycle: a simple path in which the first and the last vertices are the same.

**Undirected Graph**

간선에 방향이 주어져 있지 않습니다.

**Directed Graph**

간선에 방향이 있습니다.

**Complete Graphs**

Undirect에서는 간선의 갯수가 n(n-1)/2 입니다.

Directed에서는 n(n-1)입니다.

**Subgraphs**

V와 E가 상위 그래프에 모두 포함되면 Subgraph라 합니다.

그 외 adjacent, incdent on, adjacent to, adjacent from, in-degree, out-degree

**Adjacency List**

node 갯수 길이의 array의 각 node가 각자 리스트를 이루고 해당 node에서 adjacent한 node가 push_back됩니다.

```
for edge in edges:
    a, b = edge
    # a->b    
    adj[a].push_back(b)
    # Undirected면
    adj[b].push_back(a)
```

out-degree는 찾기 쉽지만 in-degree는 어렵습니다.

**Adjacency Matrix**

고대로 matrix 만드는 겁니다.

```
for edge in edges:
    a, b = edge
    # a->b
    adj[a][b] = 1
    # Undirected면
    adj[b][a] = 1
```

**Depth First Search (DFS)**

아까 나왔던 preorder tree traversal와 같습니다.

```
dfs(v): # 아주 대략적으로...
    visited[v] = True
    for w in v->links:
        if not visited[w]:
            dfs(w)
```

Adjacency List를 이용하면 간선의 갯수만큼 참조가 일어나고, 그 전에는 visit을 위해 node 갯수만큼 참조하므로 $$O(n+e)$$입니다.

Adjacency Matrix를 이용하면 한 node에 인접한 간선을 모두 찾는데 $$O(n)$$이 걸리고 node 갯수만큼 반복하므로 $$O(n^2)$$이 됩니다.

**Breadth First Search (BFS)**

Level order tree search와 같습니다.

```
bfs(v): # 아주 대략적으로...
    q = Queue()
    q.enqueue(v)
    while not q.is_empty():
        v = q.dequeue()
        for w in v->links:
            if not visited[w]:
                bfs(w)
```

시간복잡도는 DFS와 동일하게 Adjacency List에서 $$O(n+e)$$, Adjacency Matrix에서 $$O(n^2)$$입니다.

**Single Source Shortest Path**

하나의 출발점에서 각 정점까지 도달하는데 비용을 계산하여 최단경로를 구하는 것입니다.
기본적으로 Directed Graph 구조를 가지고 설명하며, Undirected일 경우 같은 weight의 directed edge 두 개로 바꾸고 시작합니다.

**Dijkstra Algorithm**

Priority Queue를 이용하여 하나의 정점으로부터 인접한 간선들을 확장해 나가는 방식입니다.
음수 가중치를 갖는 간선이 없어야 합니다.

d[v] 배열을 모두 ∞으로 초기화하고, 시작점의 d[v] 값을 0으로하고 모든 정점을 Priority Queue에 넣습니다.

Queue가 빌 때까지 minimum을 뽑고, 해당 정점에 adjacent한 정점의 d[v]값을 계산하여 업데이트합니다.

```
dijkstra(adjacency_list, v):
    d = [INF for _ in range(len(adjacency_list))]
    d[v] = 0
    q = PriorityQueue()
    for i in range(len(adjacency_list):
        q.enqueue([i, d[i]])
    while not q.is_empty():
        curr, value = q.dequeue()
        for dest, weight in adjacency_list:
            new_v = d[curr] + weight
            if new_v < d[dest]:
                d[dest] = new_v
```

실제로 priority queue를 heap으로 구현하고 visited 등 디테일이 좀 더 있고 path 구하려면 predecessor 배열 만들긴 해야하는데 아무튼 이런 식으로하면 됩니다.

heap에 삽입이 $$O(logE)$$, 그리고 삽입이 정점 갯수에 한해서 이루어지므로 $$O(VlogE)$$, 값 갱신은 간선 갯수에 한해서 이루어지므로 $$O(ElogE)$$,
합쳐서 $$O((E+V)logE)$$, $$V <= E^2$$이므로 $$O((E+V)logV)$$입니다. 피보나치 힙을 사용하면 더 줄일 수 있다고 하네요.

정당성 증명

방문된 정점까지의 거리는 최소 거리임을 증명하면 되는데, 초기에 정점 하나만 있을 때 만족하므로 귀납법 + 귀류법으로 풉니다.

K+1 단계에서 정점 u를 방문하였는데 그 거리가 실제 최소 거리가 아니라고 하면, 다른 정점 u'가 방문되지 않은 채 존재하여 u까지의 실제 최소 거리를 잇는 정점으로 존재한다는 것인데,
그렇게 되면 (중략 w, w'가 등장하는 부분) d[u']가 d[u]보다 작게 되는데 그러면 알고리즘 진행과정에서 u'가 u보다 먼저 방문되었어야 하므로 contradiction이 생기므로 증명 완료됩니다.

**Floyd-Warshall's Algorithm**

얘는 Single Source Shortest Path 뿐만 아니라 All Pairs Shortest Paths를 구해줍니다.

```
floyd_warshall():
    for i in range(E):
        for j in range(E):
            for k in range(E):
                if adj[i][k] > adj[j][i] + adj[i][k]:
                    adj[j][k] = adj[j][i] + adj[i][k]
```
코드만 보셔도 아실 겁니다. $$O(E^3)$$ 입니다. 중요한 점은 가운데 지나가는 정점이 맨 바깥 for문에 위치해야 한다는 것입니다.


**Minimum Cost Spanning Tree**

connected graph G에서 모든 node를 방문하는 cycle이 없는 subgraph를 spnning tree라고 합니다.

weighted undirected graph에서 spanning tree의 모든 간선의 weight 총합이 경우의 수 중 최소라면 해당 tree를
Minimum Cost Spanning Tree라고 부릅니다. (spanning tree with minimum cost)


**Kruskal's Algorithm**

1. edge를 지우고 정점을 독립적인 집합인 forest로 만듭니다.
2. edge를 ascending order로 정렬합니다.
3. cycle을 만들지 않는 가장 작은 edge를 골라 graph에 추가합니다.

```
E(G)를 ascending order로 정렬한다.
T = (V, 공집합) # vertices + no edges
VS =[[v] for v in V]
While num(VS) > 1 and (E(G) is not empty):
    (v, w) = deleteMin(E(G))
    if Find(u) != Find(v):
        replace set(u), set(v) by Union(set(u), set(v))
        add (v, w) to T
```

간선을 정렬하는데에 $$O(ElogE)$$,
그리고 Union과Find가 E번 반복되는데, Union-by-height과 path-compression을 이용하면 Union은 $$O(1)$$ Find는 $$O(log{\star}V)$$가 됩니다.
그렇게 아무튼 $$O(ElogE) + O(Elog{\star}V) = O(ElogE)$$가 됩니다.

크루스칼 알고리즘 정당성 증명

1. 크루스칼로 만들어진 그래프가 Spanning Tree 임은 Acyclic하고 모든 노드를 포함한다는 점으로 간단하게 증명됩니다.
2. Minimum Spanning Tree

귀류법을 통해 크루스칼로 만들어진 트리 T가 MST가 아니라고 합시다. 먼저 알고리즘 시작단계의 공집합에서는 MST를 만족하는데,
어느 순간 크루스칼이 택하는 간선이 아닌 다른 간선 (u, v)가 추가됨으로 MST를 만들게 된다는 의미인데 우리는 간선을 최소 weight 순으로 정렬하고 포함시켰으며
만들어지는 트리가 Spanning Tree 임은 1로 증명되었으므로 모순이 됩니다.

**Prim's Algorithm**

```
prim():
    Q = V - {s}
    For v in V:
        D[v] = INF
        v.predecessor = None
    D[s] = 0
    while not Q.is_empty():
       u = Q.extract_min()
       for v in adj[u]:
           if v in Q and w(u,v) < D[v]:
               D[u] = w(u, v)
               v.predecessor = u    
```

크루스칼의 정점 버전입니다. heap으로 구현하면 $$O((E+V)logV)$$, array를 이용하면 $$O(V^2)$$입니다.

증명

귀류법+귀납법을 사용합니다. K+1번째에 (u, v)를 추가하여 T를 만들면, (u, v)는 실제 MST T'에 포함되지 않아야 합니다.
그러므로 (u, v)를 T'에 추가하면 cyclic한 graph가 됩니다. (u, v)와 T'가 (u, v) 대신 가진 간선을 바꿨을 때
T는 전보다 weight이 더 커지게 되므로 모순입니다. (알고리즘 상)


`Sort Algorithms`{:.info}

**Selection Sort**

```
selection_sort():
    for i in range(n):
        min_idx = i
        for j in range(i + 1, n):
            if a[j] < a[min_idx]:
                min_idx = j
        a[i], a[min_idx] = a[min_idx], a[i]
```

너무 간단합니다. $$O(N^2)$$ 입니다.

**Insertion Sort**

```
insertion_sort():
    for i in range(1, n):
        key = a[i]
        j = i - 1
        while j >= 0 and a[j] > key:
            a[j + 1] = a[j]
            j -= 1
        a[j + 1] = key
```

array 앞의 초기에 1칸짜리 구역을 지정하고 한 칸씩 오른쪽으로 늘리면서 해당 item을 왼쪽 구간의 올바른 위치에 넣는것입니다.
마찬가지로 $$O(N^2)$$ 입니다.

**Bubble Sort**

```
bubble_sort():
    for i in range(n):
        for j in range(n - i - 1):
            if a[j] > a[j + 1]:
                a[j], a[j + 1] = a[j + 1], a[j]
```

뒤에서 i번째 칸을 위해 맨 앞부터 올바른 값을 swap을 반복하며 가져오길 반복합니다.
$$O(N^2)$$ 이고 위 두 정렬보다 성능이 더 나쁩니다.

**Merge Sort**

```
merge_sort(a):
    if n <= 1:
        return a
    mid = n // 2
    g1 = a[:mid]
    g2 = a[mid:]
    merge_sort(g1)
    merge_sort(g2)
    i1 = 0
    i2 = 0
    ia = 0
    while i1 < len(g1) and i2 < len(g2):
        if g1[i1] < g2[i2]:
            a[ia] = g1[i1]
            i1 += 1
            ia += 1
        else:
            a[ia] = g2[i2]
            i2 += 1
            ia += 1
    while i1 < len(g1):
        a[ia] = g1[i1]
        i1 += 1
        ia += 1
    while i2 < len(g2):
        a[ia] = g2[i2]
        i2 += 1
        ia += 1
    return a
```

분할정복으로 분해된 sub-array들을 한 쌍씩 쭉 합쳐주는겁니다.
$$O(NlogN)$$ 이지만 같은 시간복잡도의 다른 정렬들과 다르게 추가적인 memory를 필요로 합니다.

**Quick Sort**

```
quick_sort(a, start_idx, end_idx):
    if len(a) <= 1:
        return a
    else:
        pivot_idx = start_idx + (end_idx - start_idx) // 2
        pivot_val = a[pivot_idx]
        a[pivot_idx], a[end_idx] = a[end_idx], a[pivot_idx]
        store_idx = start_idx
        for i in range(start_idx, end_idx):
            if a[i] < pivot_val:
                a[i], a[store_idx] = a[store_idx], a[i]
                store_idx += 1
        a[store_idx], a[end_idx] = a[end_idx], a[store_idx]
        quick_sort(a, start_idx, pivot_idx - 1)
        quick_sort(a, pivot_idx + 1, end_idx
```

$$O(N)$$의 extra memory를 허용하게 하면 더 쉽게할 수 있지만 위처럼 만들면 extra memory는 starck frame의 $$O(logN)$$ 만 필요합니다.

평균적으로 $$O(NlogN)$$ 의 시간복잡도를 가지지만, 최악의 경우 $$N^2$$ 의 시간복잡도를 가집니다.

시간복잡도에 대한 증명은 [여기](https://www.khanacademy.org/computing/computer-science/algorithms/quick-sort/a/analysis-of-quicksort)를 참고하세요.
근데 교수님 수업에서 적분까지 해가면서 strict하게 증명했던 것 같은데 필기가 남아있지 않네요... 나중에 그때 그 내용 어디서 찾으면 추가할게요.

**Heap Sort**

```
heapify(a, idx, heap_size):
    largest = idx
    left_idx, right_idx = 2 * idx + 1, 2 * idx + 2
    if left_idx < heap_size and a[left_idx] > a[largest]:
        largest = left_idx
    if right_idx < heap_size and a[right_idx] > a[largest]:
        largest = right_idx
    if largest != idx:
        a[largest], a[idx] = a[idx], a[largest]
        heapify(a, largest, heap_size)


heapsort(a):
    n = len(a)
    for i in range((n - 1) // 2, -1, -1):
        heapify(a, i, n)
    for i in range(n - 1, 0, -1):
        a[0], a[i] = a[i], a[0]
        heapify(a, 0, i)
```

이건 코드를 좀 열심히 봐야 이해가 가더군요. 일단 `heapify()` 는 heap을 array로 표현했을 때 idx 위치에 있는 node의
left child, right child와 비교해서 더 셋 중 가장 큰 node를 parent 자리에 위치시키는 겁니다. 이걸 array의 뒤에서부터 해주면 아래에서 자리가 올바르지 않은 node 들이 쭉 올라와서 제자리를 찾으며 정렬이 됩니다.
그리고 두 번째 for문에서는 정렬된 heap에서 max 값인 root를 반복적으로 추출해서 array의 뒤에 위치시키는 겁니다.

complete binary tree에서 left child가 `2*idx+1`, right child가 `2*idx+2`를 index로 가지는 것은 귀납법으로 증명 가능하며,
heapify를 `(n-1)//2`부터 하는 이유는 해당 node가 바로 child를 가질 수 있는 마지막 node이기 때문입니다.


**Topological Sort**

Directed Graph에서 정점들의 선행 순서를 위배하지 않으면서 모든 정점을 나열하는 알고리즘입니다.
Scheduler처럼 작업의 순서가 정해져 있을 때 각각의 작업이 완료되어야 끝나는 문제에 주로 쓰입니다.

```
topological_sort():
    q = Queue()
    for i in range(n):
        if in_degree[n] == 0: 
	    q.enqueue(i)
    for i in range(n):
        if q.is_empty():
            error
        x = q.dequeue()
        answer[i] = x
        for j in adj[x]:
            in_degree[j] -= 1
            if in_degree[j] == 0:
                q.enqueue(j)
```

BFS랑 비슷한데, inDegree를 이용하여 enqueue 합니다. 시간복잡도는 $$O(V+E)$$ 입니다.


`Hashing`{:.info}

**Hashing**

Hashing이란 Hash Function을 이용해 item의 index를 item의 key를 이용해 결정하는 것입니다.

**Collision**

간단하게 array length로 나눠 나머지를 index로 이용하는 방법이 있으며
서로 다른 item이 같은 위치로 배정되는 collision이 일어날 수 있습니다.

**Linear Probing**

collision이 일어난다면 empty spot을 찾을 때까지 선형 이동하여 해당 index로 이동시킵니다.

**Search**

hash function을 통해 index를 찾고 해당 key와 동일한 지 이동해가며 찾습니다.

**Delete**

삭제를 할 때에는 해당 index를 빈 공간으로 만들지만 marking하여 원래 item이 있던 곳임을 표시합니다.

**Double Hashing**

hash function 두 개를 사용해서 collision이 일어나면 hash2로 다음 spot을 찾습니다.

**Chained Hashing**

collision이 일어나도 해당 index에서 linked-list를 형성하며 위치시킵니다.

삽입/삭제/탑색의 시간복잡도가 사실 $$O(1)$$ 은 아닌데 그렇다고 봐도 무방합니다...

**Dynamic Array**

처음엔 작은 길이의 array를 할당하여 사용하고, 해당 사이즈를 넘어가는 삽입이 일어나면 길이를 두 배로 늘린 array를 할당하여 item을 다 옮겨주길 반복합니다.

amortized analysis를 통해 놀랍게도 삽입의 시간복잡도가 $$(nO(1) + O(n))/(n+1) = O(1)$$ 이 됩니다.

`String-related Algorithms`{:.info}

**String Matching**

주어진 긴 문자열(길이 m)에서 특정 문자열(길이 n)의 등장 위치를 찾는 알고리즘들입니다.

**Brute Force Algorithm**

모든 상황을 다 검색한다는 의미로 더 크게 쓰이기도 하지만 string matching에서는 앞에서부터 차례대로 검색하는 것입니다.

```
bruteforce():
    for i in range(len(text) - len(pattern) + 1):
        j = 0
        while j < len(pattern) and pattern[j] == text[i + j]:
            j += 1
        if j == len(pattern):
            print(i)
```

시간복잡도는 $$O((n - m + 1)m)$$ 인데 보통 $$n >> m$$ 인 상황이 많으며 그럴 때는 $$O(nm)$$ 입니다.

**Rabin-Karp Algorithm**

Hashing을 이용한 알고리즘입니다.

Rabin Fingerprint라는 hash function을 사용합니다.
alphabet의 길이를 d 라고 하고, pattern을 d-항식으로 두고 갑을 계산합니다.
그리고 Text의 subword에 같은 방법으로 값을 계산하여 비교하는 것입니다.

하지만 이렇게 하면 hash값이 너무 커질 수 있으니 적당한 prime number를 사용해 modular 값을 이용합니다.
그리고 False-Positive를 피하기 위해 해시값이 같을 때 문자열을 직접 비교하고 결과에 추가합니다.

```
rabin_karp():
    h = hash(pattern)
    for i in range(len(text) - len(pattern) + 1):
        if h == hash(text[i:i + len(pattern)]):
            j = 0
            while j < len(pattern) and pattern[j] == text[i + j]:
                j += 1
            if j == len(pattern):
                print(i)
```

이렇게 하면$$O(nm)$$ 입니다만, [Horner's scheme](https://en.wikipedia.org/wiki/Horner%27s_method)을 사용하면 hash값이 한 step 전의 hash값으로 부터 $$O(1)$$에 계산하고,
hit의 경우가 엄청 큰 경우가 아니라면 $$O(n + m)$$ 에 가까워집니다.


**Boyer-Moore Algorithm**

브루트포스처럼 왼쪽에서 오른쪽을 패턴을 이동시키지만 문자 일치 검사는 패턴의 오른쪽부터 합니다.

이 때 3가지의 Bad Character Heuristic을 가집니다.

1. text의 character가 pattern 내에 없는 경우 pattern을 그 character 너머로 이동시킵니다.
2. text의 character가 pattern 내에 있을 경우 pattern 안의 가장 오른쪽의 character와 해당 character를 대치하도록 이동시킵니다.
3. 아니면 한칸이동합니다.

이렇게 해도 worst case의 경우 브루트포스와 같은 $$O(nm)$$ 을 가지지만 average case는 $$O(n/m)$$ 으로 줄일 수 있다고 합니다. 이 계산 증명은 아직 알아보지 않았습니다. 상대적으로 좋은 heuristic이기 때문에 속도가 더 빠르다고 볼 수 있습니다.

뿐만 아니라 Good Suffix Heuristic도 사용하는데, Pattern 내부에서 suffix가 prefix로 등장할 경우,
매칭이 되다가 miss가 나왔을 시 1칸만 움직이는 것이 아니라 prefix를 suffix가 매칭되던 위치로 이동시킬 수 있습니다. 이와 같은 경우를 고려하기 위해
Text를 훑기 전, Pattern의 miss가 나는 위치에 따라 몇 칸을 이동시켜야하는지 미리 계산해두고 사용하는 것입니다.

두 Heuristic을 같이 사용하므로 둘 모두 고려하여 최대 이동거리를 사용합니다.


**Edit Distance**

"LewenStein distance", 주어진 문자열 u, v가 얼마나 다른지 파악하는 것입니다. delete, insert, replace 3가지 operation을 기준으로  몇 번의 oepration을
통해 u를 v로 변환시키는지 d(u, v)로 표현합니다. rule은 여기 옮기지 않겠지만 dynamic programming으로 해결합니다.


**Trie**

Set of Strings을 위한 Data Structure 입니다. 

alphabet의 길이를 d라고 할 때, d-ary tree 구조를 가집니다.

edge에 character가 label되었다고보고, 모든 정점은 해당 정점까지 path의 string을 의미합니다.

구현 방식으로 array를 이용하여 d 길이의 array가 각 vertex를 의미하게 만드는 방법과
linked list를 이용하는 방법이 있습니다.

공간복잡도는 string의 종류를 m이라 할 때 array를 이용하면 $$O(md)$$, linked-list를 이용하면 $$O(m)$$ 입니다.

탐색/삽입/삭제의 시간복잡도는 linked-list의 경우 outdegree를 전부 확인해야하므로 $$O(md)$$, array는 $$O(m)$$이 됩니다.

Linked-list의 경우 edge에 길이가 1 이상인 string을 부여하여(compress paths) 효과적인 구조로 만들 수 있습니다.


**Suffix Tree**

Trie와 비슷해보이지만 string(+ 끝을 뜻하는 "$")의 모든 suffix의 집합을 이용하여 만든 tree입니다.
edge에는 string, node에는 index를 표시합니다. construct 시간복잡도와 공간복잡도는 $$O(n^2)$$ 입니다.

String Matching에 사용되는 경우 pattern(edge 중간에 끊길 수도 있습니다)을 찾고 해당 path에서 나오는 모든 leaf node의 index에 해당 pattern이 존재합니다.

시간복잡도는 $$O(n + m)$$ 입니다.

`Dynamic programming`{:.info}

**Dynamic Programming**

엄밀히 말하자면 알고리즘은 아니고 알고리즘 설계 기법입니다.
답을 구하기 위해서 했던 계산을 또 하고 또 해야하는 류의 문제(Optimal Substructure)를 위해 memoization을 통해 한번 계산한 결과를 메모리에 저장해 두었다가
꺼내 쓰는 것입니다. 대표적으로 피보나치 수열을 푸는 문제의 경우 시간복잡도를 $$O(2^n)$$ 에서 $$O(n)$$ 으로 줄일 수 있습니다.

[관련 문제](https://www.acmicpc.net/problem/tag/%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9%20%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D)를 풀고 몸에 익히는 것이 중요합니다.


## PL

`Static scope and Dynamic scope`{:.info}

**Static Scope**

Static Scope는 우리가 접하는 대부분의 언어에서 사용되는 방식으로 function이 정의된 곳의 environment를 사용하는 것입니다. 아래의 dynamic scope가 어떻게 다른지만 보시면 되겠습니다.

**Dynamic Scope**

반면에 Dynamic scope는 function이 call 된 곳의 environment를 function이 사용합니다.

```
{deffun {f p} n}
{with {n 5} {f 10}}
```

제 편의(;;)를 위해 수업에서 사용한 scheme 언어를 사용하면, 위와 같은 코드는 dynamic scope라면 `n`의 값이 함수 내에서도 사용되므로 `5`을 return하고 static scope에서는 error를 뱉게 됩니다.


`First-order functions and First-class functions`{:.info}

**First-order Functions**

```
f(x) = 1 + x
```

C에서 함수를 정의하고 사용하는 방식을 생각하시면 됩니다. 그리고 아래의 first-class function을 보고 차이점을 이해합시다.

**First-class functions**

```
f = λx. 1 + x
```

Python에서 함수를 괄호없이 불러서 변수에 저장하는 방식이나, Javascript에서 const로 함수를 정의하여 `() => ...` 등의 문법을 사용하는 것을 예시로 들 수 있습니다.
C에서도 함수포인터를 이용하여 비슷한 효과를 낼 수 있지만 function이 first-class object로 취급되는 언어를 이용하면 후에 Higher-order function (ex. map())을 사용할 수 있습니다.


`Calling Convention`{:.info}

**Calling Convention**

함수가 호출될 때, 메모리 공간 안에서는 함수 내부의 명령어를 실행하며 사용하기 위한 Stack Frame이 할당됩니다.
이 때 parameter가 어떤 방식으로 전달되는지 아래의 여러 방식이 있습니다. 실제 Calling Convention은 parameter 전달 방법 뿐만 아니라
전달 순서, return value 전달 방법, stack frame 정리 방법, 이렇게 4가지가 있지만 parameter 전달 방법만 다루겠습니다.

**Call by Value**

C에서는 사실상 모든 상황에 Call by Value가 이용됩니다. Java를 예로 들면 primitive type인 int, short, long, float, double, char, boolean에 대해서 적용되며, value를 복사하여 함수의 인자로 사용합니다.
swap 함수를 사용할 때 cadll by value가 적용되면 swap이 되지 않습니다.

**Call by Reference**

value를 복사하는 것이 아닌 해당 variable을 직접 전달하는 것입니다. C에서 변수에 &를 붙인 채 함수를 정의할 때와 같은 효과를 가집니다.
Java에서 reference type인 Array, Class에 대해 적용됩니다.

**Call by Address**

C에서 포인터를 이용해 주소를 전달하는 것입니다. pointer를 쓰지 않는 언어에서는 언급되지 않는 것 같습니다.. 이 부분은 확실하게 확인하지 못했습니다.

**Call by Assignment**

Python의 경우 모든 상황에 Call by Assignment가 사용됩니다. 먼저 int, float, str, tuple은 immutable object, 그리고 list, dict, set은 mutable object로 분류하는데,
mutable object는 call by reference를 적용시키고 immutable object의 경우 처음에는 call by reference를 이용하다 값이 변경되면 call by value로 전환됩니다.

**Call by Name**

Call by name을 이용할 경우 argument는 function call 즉시 계산되는 것이 아니라 필요시에 계산되게 됩니다.


`Lazy Evaluation`{:.info}

**Lazy Evaluation**

```
def some_function(x, y):
    return x + 1

some_function(3, 3 + 2)
```

위와 같은 코드를 실행한다고 합시다. strict evaluation에서는 some_function이 call 되는 순간 3 + 2 가 계산되어야 하지만 lazy evaluation에서는 해당 parameter 값이 필요할 때에 계산합니다.
고로 위 코드에서는 y가 필요없으므로 계산하지 않고 더 높은 성능을 보일 수 있습니다.

위의 예시는 정말 간단한 경우이지만, list의 head 값을 알기 위해 quick sort를 사용할 시에 head 값이 결졍되는 대로 나머지 계산은 하지 않기도 하며, python의 if문에 여러 condition을 부여했을 때 검증이 필요없어진 condition은
evaluation 하지 않고, infinite list에 대해서도 모든 item의 계산이 필요하지 않을 때 handling이 가능해집니다.

Lazy Evaluation이 적용될 경우 해당 parameter가 함수 내의 여러 번 사용되는 경우 evaluation이 여러 번 일어나는 것을 예방하기 위해 caching 이 일어납니다.


`Tail recursion and fibonacci programming`{:.info}

**Tail Recursion**

```
def sum(n):
    if n == 0:
        return 0
    else:
        return n + sum(n - 1)


sum(4)
```

위와 같은 코드를 실행한다고 합시다. 그럼 코드의 실행은 이런 식으로 전개됩니다.

```
sum(4)
4 + sum(3)
4 + (3 + sum(2))
4 + (3 + (2 + sum(1)))
4 + (3 + (2 + (1 + sum(0))))
4 + (3 + (2 + (1 + 0)))
4 + (3 + (2 + 1))
4 + (3 + 3)
4 + 6
10
```

이런 식으로 전개되며 stack frame은 sum n개가 쌓임을 볼 수 있습니다. 함수 내에서 두 번의 호출이 일어나는 fibonacci 함수는 $$2^n$$ 개의 stack frame이 쌓입니다.

반면에 아래와 같이 함수를 정의한다고 합시다.

```
def sum(n, acc):
    return 0 if n == 0 else sum(n - 1, acc + n)


sum(4, 0)
```

이렇게 정의한다면 if문이 먼저 검증되고 sum() 함수가 호출되며 return 값이 돌아온 이후에 해야할 operation은 그대로 return 하는 것밖에 남지 않습니다.

```
sum(4, 0)
sum(3, 4)
sum(2, 7)
sum(1, 9)
sum(0, 10)
10
```

코드의 실행은 이런 식으로 전개되며 됩니다. javascript engine이나 jvm, cpython은 기본적으로 tail recursion optimization을 지원하지 않아 stack-frame이 4개 그대로 생성되지만
gcc나 functional programming language는 tail recursion optimization을 지원하여 return 값을 받은 후 추가적으로 해야할 operation이 없는 경우 stack-frame을 덮어씌워 새로 생성하지 않고
recursion을 iteration으로 변환합니다.


`Garbage collection (GC)`{:.info}

**Garbage Collection (GC)**

C나 C++ 같은 low-level(엄밀히 말하자면 C++는 High level 입니다만) language는 변수선언, `malloc()`과 `free()`를 통해 메모리 할당과 해제가 직접 이루어집니다.
반면에 Python이나 Javascript 같은 high-level language는 Garbage Collector가 자동으로 활동하며 메모리 해제를 해줍니다.

중요한 점은 GC가 할당된 메모리에 대해 특정 시점에서 필요유무를 판단하고 해제하는 방식입니다.

CPython에서는 Reference Counting을 기반으로 한 GC가 돌아간다고 합니다.


**Reference Counting**

- 모든 record(data를 담은 structure)에 대해 초기에 count 0를 부착합니다.

- 해당 record를 가르키는 pointer(이또한 record)가 생성될 때 record의 count에 1을 더합니다.

- 해당 record를 가르키는 pointer가 다른 곳을 가르키거나 사라지면 count에 1을 뺍니다.

- record의 count가 0이 되면 해당 record가 가르키는 record들의 count에서 모두 1을 빼고 기존의 record를 free 해줍니다. (root record는 제거하지 않습니다.)

여기서 root record란 모든 global variable들과 현재 실행되는 함수 내의 모든 local variable을 뜻합니다. 얘네들은 free 되지 않으므로 위 알고리즘이 성립할 수 있습니다.

명시적이든 암시적이든 A라는 memory를 통해 B라는 memory를 통해 B라는 memory에 접근할 수 있다면 그것이 명시적이든 암시적이든 B는 A에 의해 reference 된다고 정의합니다.
예를 들어 Javascript object는 prototype을 암시적으로 참조하죠. 그리고 기존의 Javascript object 뿐만 아니라 function scope도 포괄됩니다.

**Limitations**

Cycle이 발생할 경우 free 해줄 수 없습니다. 실제로 IE6, 7은 이 reference counting algorithm을 이용하며 다음과 같은 메모리 누수가 발생합니다.

```javascript
// div object는 EventHandler인 onclick 속성을 통해 참조되며, EventHandler scope에도 div object가 있으므로 cycle이 발생합니다.
var div = document.createElement("div");
div.onclick = function(){
    doSomething();
};
```

count를 유지하는 것은 시간을 잡아먹습니다.

locality가 좋지 않답니다.

free list를 만들어 available memory를 track 해줘야 합니다.

**Mark & Sweep Garbage Collection**

- 모든 record를 흰색으로 칠합니다.

- root로 인해 reference된 record들은 회색으로 칠합니다.

- 아래 과정을 회색 record가 없어질 때까지 반복합니다.
  - 회색 record r을 고릅니다.
  - r이 가르키는 모든 흰색 record를 회색으로 칠합니다.
  - r을 검은색으로 칠합니다.

- root를 제외한 모든 흰색 record를 free합니다.

**Limitations**

Cycle에 의해 생기는 문제는 해결하지만 Reference Counting의 나머지 문제점은 해결하지 못합니다.

- Cost가 heap 전체에 비례하게 됩니다.
- Locality가 좋지 않습니다.
- free list를 유지해야 합니다.


**Two-Space Copying Collectors**

`to-space`, `from-space` 두 메모리 공간으로 나누어 이용합니다.

- Allocator:
  - memory를 `to-space`와 `from-space`로 파티션합니다.
  - 메모리 할당을 `to-space`로만 합니다.
- Collector:
  - `to-space`와 `from-space`의 record를 스왑해줍니다.
  - Mark & Sweep에서 회색으로 칠하는 역할을 대신 `from-space`에서 `to-space`로 보내줍니다.
  - 회색 record를 고르는 것은 `to-space`에서만 시행합니다.


`Lambda algebra`{:.info}

**Lambda Algebra, Lambda Function**

이는 Anonymous Function이면서 First-class Function을 부르는 말입니다.

`Type System`{:.info}

- Type system and type checking, strong/weak type, dynamic/static type checking

**Type System**

Type System은 variable, expression, function, module 등 프로그램의 구성품들에 Type을 부여하는 것입니다.
기본적으로 Type System의 목적은 버그를 Runtime 이전에 미리 포착하고 방지하기 위함입니다. (동적 타입 언어는 Runtime에 Type Check가 이루어집니다.)


**Polymorphic Types**

Typecheck 중 `(alpha -> alpha)` 와 같은 타입은 어떠한 타입도 될 수 있는 alpha를 받고 해당 타입을 return한다는 뜻입니다.
따라서 명확히 적으면 `∀ alpha (alpha -> alpha)` 이 됩니다.


**Statc Type / Dynamic Type Checking**

Static Type Checking Language에서는 Typecheck가 compile time에 이루어지며 Dynamic type에서는 runtime에 이루어집니다.

**Strong Typed / Weak Typed Language**

Strong Typed Language 에서는 암묵적 형변환을 허용하지 않습니다.

근데 제가 찾다보니 이 부분은 사람들마다 생각하는게 다른 것 같은데(;;) 이건 각잡고 다시 알아봐야겠습니다.

**Type Soundness / Type Completeness**

- Type Soundness: 모든 well-typed program은 error를 만들지 않는 올바른 program 입니다. (no false negative)
- 모든 올바른 program은 type-check에 통과합니다. (모든 ill-typed program은 incorrect program 입니다. => no false positive)


`Compiler, interpreter`{:.info}

**Compiler**

- Program을 통해 program을 만들어냅니다.

**Interpreter**

- Program을 통해 result를 만들어냅니다.

**Compiled Language**

- Runtime 이전에 Assembly Language 등으로 변환되는 언어입니다.

**Interpreted Language**

- Runtime 중에 Instruction 단위로 interpret 되는 언어입니다.


## Network

- Packet Switching vs Circuit Switching

서킷 스위칭은 대표적으로 전화에서 쓰이는 데이터 전달 방법입니다. 전화는 시간단위로 요금을 청구하며 실시간성이 중요하기 때문에,
중간에 누군가 그 회선에 끼어들면 안되며 서킷 전체를 독점하며 속도도 일정하게 됩니다.

패킷 스위칭은 데이터를 패킷단위로 쪼개서 보내는 것이며, 서킷을 독점하지 않고 공용선을 이용합니다.

`How Internet works?`{:.info}

Internet은 IP(Internet Protocol), TCP(Transport Control Protocol) 등 프로토콜에 합의된 방식으로
Packet을 주고 받는 거대한 네트워크입니다.

**What's a protocol**

프로토콜은 컴퓨터가 네트워크 내에서 어떤 방식으로 통신해야하는지 정한 규칙의 집합입니다.

**What's a packet**

Internet으로 전달되는 데이터를 Message라고 할 때, Message가 전송될 때, 먼저 해당 Message를 packet이라는 조각으로 잘게 나눕니다.
이 패킷들은 서로 독립적으로 전송되며 IP(Internet Protocol)은 어떤식으로 패킷화되어야 하는지 명시하고 있습니다.

**What's a packet routing network**

Packet Routing Network란 패킷을 시작 지점 컴퓨터로부터 도착 지점 컴퓨터까지 전달하는 네트워크입니다.
인터넷은 수많은 Router들로 이루어져 있으며 각 router의 역할은 패킷을 출발지점으로부터 목적지로 옮기는데에 있습니다.
패킷은 도착지까지 도달하기 위해 다수의 Router를 지나게 됩니다.

한 Router로부터 다음 Router까지 이동하는 것을 Hop이라고 부릅니다.
Internet Protocol에 의하면 Router는 packet의 header에 adderess를 명시하여 보내야 합니다.

**Where did these Internet routers come from? Who owns them?**

1960년대 ARPANET이 인터넷의 시초가 된 이후 ISP(Internet Service Providers)가 router들을 네트워크 내로 추가하였습니다.
인터넷 라우터의 주인이 되는 개인은 없습니다. ARPANET 이후 정부기관, 대학, AT&T와 같은 기관이 router를 점진적으로 추가하였습니다.

**Do the packets always arrive in order? If not, how is the message reassembled?**

Internet Protocol은 패킷이 목적지에 도달한다는 것에 대해 확신을 제공하지 않습니다. Packet Loss 가 일어날 수 있습니다.
Transport Control Protocol은 packet loss를 retransmission으로 해결합니다. 도착지에서 출발지점으로 ACK 패킷을 보내게 합니다.
도착지에서 누락된 패킷이 있음을 인식하면 출발지에 retransmission을 요청합니다. 이 과정은 사실 더 복잡한데 아래에서 차근차근 다루겠습니다.

**What do these Internet addresses look like?**

이 주소들은 IP 주소로 불리며 2가지 표준이 있습니다.

IPv4는 예를 들어 `212.78.1.25`와 같이 생겼으며 이는 IPv4가 $$2^{32}$$개의 주소값을 허용하기 때문이며,
새로 제시된 IPv6 표준에서는 주소가 `3ffe:1893:3452:4:345:f345:f345:42fc`와 같이 생겼으며 $$2^{128}$$개의 주소값을 허용합니다.
2014년 구글에 의하면 당시 IPv6 트래픽은 전체의 3% 밖에 되지 않았다고 합니다.

**How can there be over 8 billion networked devices on the Internet if there are only about 4 billion IPv4 addresses?**

이유는 public IP address와 private IP address가 존재하기 때문입니다. Local Network로 접속하는 기기들은 같은 public IP address를 공유합니다.
그리고 이 local network 내에서 기기들은 서로 다른 private IP address로 구별됩니다.
일반적으로 `192.168.xx`, `172.16.x.x`, `10.x.x.x` 등의 구조를 가집니다. 그리고 이 private IP address는
Dynamic Host Configuration Protocol (DHCP)에 의해 할당됩니다.

예를 들어 같은 local network 내에 있는 노트북과 스마트폰으로 `www.google.com`에 요청을 보낼 시, 모뎀을 떠나는 패킷은 패킷 헤더에 기기에 배정되는 포트번호를 담고,
응답이 돌아왔을 시 그 포트번호를 이용해 올바른 기기에게 응답을 전달해줍니다.

private IP address를 public IP address에 매핑하는 프로토콜은 NAT(Network Address Translation) protocol을 통해 이루어집니다.

이 관점에서 IP address는 기기에 특수하게 부여되지 않은 것으로 보입니다. 기기에 유니크하게 부여되는 주소는 MAC address 입니다.
MAC address는 기기의 life를 통틀어 하나로 특정됩니다.

**How does the router know where to send a packet? Does it need to know where all the IP addresses are on the Internet?**

라우터는 IP 주소가 어디를 가르키는지 전부 알지는 못합니다. 오직 Outbound Link 라 불리는 이웃한 주소만 알고 있죠.

IP address는 Network Prefix와 Host Identifier 두 부분으로 나누어 집니다.

예를 들어 `129.42.13.69`는 아래와 같이 나누어집니다.

```
Network Prefix: 129.42
Host Identifier: 13.69
```

대학, 기관, ISP(Internet Service Provider) 등 큰 단위의 단일 위치로 연결되는 라우터들은 모두 같은 Network Prefix를 가집니다.

모든 라우터는 `129.42.*.*` 형식의 IP address를 같은 곳으로 먼저 보내게 되는것이죠. 이 방법으로 라우터가 기억해야할 주소는 확 감소됩니다.

**If a new router is added to the Internet how does it know how to handle packets for all these network prefixes?**

새로 설치된 라우터가 패킷을 어디로 라우트해야할 지 모르는 경우가 나올 수 있습니다. 그럴 때는 라우터가 이웃하는 라우터들에게
해당 패킷을 전송해야할 곳의 정보를 알고 있는지 쿼리를 보냅니다. 그리고 이웃한 라우터들은 정보를 파악하여 시작점이었던 라우터에게 되돌려 줍니다.
그리고 라우터는 그 정보를 저장하여 다음에 바로 전송할 수 있도록 준비합니다. 이 알고리즘은 원래 더 복잡한데 생략합니다.
이 방법으로 라우터는 Routing Table이라는, Network Prefix와 Outbound Link를 묶은 정보들을 가집니다.

**How do networked computers figure out IP addresses based on domain names?**

컴퓨터는 `www.google.com`과 같은 domain name을 이용해 IP address를 얻어내야 합니다.
이는 Domain Name System(DNS)를 이용해 이루어집니다.

IP address를 얻기 위해 컴퓨터는 먼저 local DNS cache를 참조합니다. local DNS cache에는 최근 방문했던 domain name과 IP address가 저장되어 있습니다.
캐시에서 찾아내지 못했거나, 해당 IP address 기록이 만료되었다면(TTL: Time To Live가 처음 요청을 받아올 때 적혀옵니다.) ISP의 DNS server로 요청을 보냅니다.
같은 방식으로 ISP의 DNS server에서도 IP address를 구하지 못하면 Root Name Server로 요청을 보냅니다.
Root Name Server는 해당 도메인의 IP를 전부 갖고 있진 않고 주소 맨 오른쪽에 있는 `.com` `.net` 같은 Top-level Domain을 보고 해당 도메인들을 관리하는 서버의 주소를 알려줍니다.
그를 통해 ISP는 해당 Top-level Domain 관리 서버로 요청을 보내 IP address를 받아옵니다.

**How do applications communicate over the Internet?**

Internet은 몇 개의 층으로 나눌 수 있습니다. OSI 7 Layer나 TCP/IP 4 Layer가 있지만 여기서는 후자의 구조를 거론하겠습니다.
Internet은 Internet Network Layers로 나뉘며 Link Layer, Internet Layer, Transport Layer, Application Layer가 있습니다.
이들이 Layer라 불리는 이유는 각 레이어가 다른 레이어 위로 쌓아 올려졌기 때문이며, 각 레이어는 해당 레이어 아래 레이어들의 기능을 상세히 고려하지 않고도 모두 포함하며 작동합니다.

![](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/interview/0.png){:width="350px"}

Internet Application은 Application Layer에 기반하여 작동하며 그 아래 레이어들의 기능을 자세히 고려하지 않아도 됩니다.
예를 들어, 어플리케이션이 네트워크 다른 어플리케이션과 TCP를 이용하여 통신할 때는 Socket이라는 구조를 이용하며, 이는 packet routing과 re-assembling의 복잡한 구성에 대한 걱정을 없애줍니다.

**What do each of these Internet Layers do?**

- Link Layer

가장 낮은 레벨의 Link Layer는 "physical layer"라고도 불리며 데이터를 bit 단위에서 케이블이나 wifi signal을 통해 어떻게 전달되는지를 고려합니다.

- Internet Layer

Link layer 위에는 Internet Layer가 위치합니다. Internet Layer는 패킷을 목적지로 라우팅하는 것을 고려합니다.
앞의 언급된 Internet Protocol이 이 레이어에서 사용합니다. Internet Protocol에 따라 network load나 outage를 따져 패킷의 목적지를 동적으로 조정하고 reroute합니다.

- Transport Layer

그 위로는 Transport Layer가 있습니다. 이 레이어에서는 아래의 Internet과 Link Layer에서 data 전송이 완전히 되지 않을 시를 위해 보정하는 작업이 일어납니다.
Transport Control Protocol(TCP)에 따라 packet loss에 반응하여 해당 packet을 재전송합니다.

- Application Layer

맨 위에는 Application Layer가 있습니다. 이 레이어에서는 아래 레이어들의 복잡한 패킷 통신 구조를 이용하여
socket과 같은 간단한 구조로 인터넷의 다른 어플리케이션들과 통신합니다.
이곳에는 HTTP Protocol이 적용되어 웹 브라우저와 웹 서버가 어떻게 상호 작용하는지 정해집니다.
email client와 관련된 작업에는 IMAP protocol이, File-downloading client와 file-hosting server 사이의 통신에는 FTP protocol이 적용됩니다.

**What's a client versus a server?**

Client와 Server는 모두 인터넷을 통해 통신하는 어플리케이션입니다.
그 중 Client는 "유저와 더 가까운 편"이라고 말할 수 있습니다. Web browser나 email client, smart phone app 등을 통해 유저를 직접 상대하는 어플리케이션이죠.
그리고 Sever는 remote computer에서 작동하며 client가 필요에 의해 통신하는 어플리케이션입니다.

**How can sensitive data like credit cards be transmitted securely over the Internet?**

초기의 인터넷에서는 서로 다른 위치에서 router와 link를 통해 네트워크 안에서 연결되어있음을 확인하면 그것만으로 충분했습니다.
하지면 이젠 인터넷의 크기가 커지고, 라우터가 늘어났습니다. 통신을 통해 거치는 라우터의 수가 늘어난다는 것은 취약한 지점이 많아짐을 뜻하고,
더 나아가 WiFi와 같이 무선통신이 이용되면서 해커들이 패킷을 허공에 뿌려서 공격할수도 있게 되었습니다.

이전의 구조만으로는 네트워크 연결이 안전한지 장담할 수 없게 되었고 그에 대한 해답으로 SSL/TLS를 통한 encryption과 authentication이 생겼습니다.

**What is SSL/TLS?**

SSL은 Secured Sockets Layer를, TLS는 Transport Layer Security를 뜻합니다.
SSL은 Netscape에 의해 1994년 생겼으며 시간이 지나 수정을 거쳐 TLS로 이름이 정정되어 현재는 SSL/TLS라는 명칭으로 합쳐서 불립니다.

SSL/TLS는 선택적으로 사용되어 Transport Layer와 Application Layer 사이에 위치합니다.
SSL/TLS는 민감한 정보를 encryption과 authentication을 통해 보호합니다.

Encryption은 client가 server로 보내는 TCP connection을 요청을 암호화하는 것을 말합니다.
message가 packet으로 나뉘기 전에 일어나기에, 해커가 packet을 가로챈다해도 기존의 message를 파악할 수 없게 됩니다.

Authentication은 client가 server로 보이는 녀석을 믿을 수 있는지 판단하는 것입니다.
이를 통해, client와 server 사이에서 악의적인 간섭을 일으키는 [Man-in-the-middle attack](https://en.wikipedia.org/wiki/Man-in-the-middle_attack)을 막을 수 있습니다.

SSL이 적용된 웹사이트는 `http`가 아닌 `https` 프로토콜을 사용합니다. 

**How does SSL authenticate the identity of a server and encrypt their communication?**

SSL은 Asymmetric Encryption과 SSL Certificate를 이용합니다.

Asymmetric Encyption은 소수로 이루어진 public key와 private key를 이용합니다.
private key는 decryption, public key는 encryption에 이용되며
"Asymmetric"인 이유는 Symmetric encryption과 달리 encryption과 decryption에 이용되는 key의 값이 다르기 때문입니다.

SSL certificate은 public key를 내장한 digital document입니다. SSL certificate는 CA(certificate authority: 인증기관)을 통해 발급됩니다.

Client가 SSL-encrypted connection을 서버에 요청할 시, 서버는 해당 요청을 SSL certificate(인증서)를 client로 먼저 보냅니다.
그리고 client는 SSL certificate을 확인하여 아래 사항들을 확인합니다.

- 인증서가 해당 서버를 담고 있는지,
- 인증서가 믿을 수 있는 CA를 통해 발급되었는지,
- 만료되지 않았는지

그 후 client는 인증서의 public key를 이용해 temporary secret key를 만들어 server로 보냅니다.
이제 server는 private key를 이용해 해당 secret key를 해석하며 양쪽은 secret key를 이용해 secret key의 기간이 만료될 때까지 encryption과 decryption을 하며 패킷을 주고 받습니다.

**What happens if a hacker intercepts an SSL-encrypted session?**

만약 해커가 client와 server 사이 message를 가로챈다면 SSL certificate과 temporary secret key를 볼 수 있지만
private key가 없으므로 secret key를 해석할 수 없으며 그러므로 message를 해석할 수 없습니다.

**Summary**

- 인터넷은 탈중앙화된 컴퓨터 네트워크를 목적으로 개발된 1960년대 ARPANET로부터 시작되었습니다.
- 물리적으로 인터넷은 wire, cable, radio signal을 이용해 bit를 전달하는 컴퓨터의 집합입니다.
- 인터넷은 각각 더 작은 문제들을 해결하는 여러 개의 레이어로 구성됩니다.
- 서로 다른 레이어에서 인터넷과 어플리케이션이 어떻게 작동하는지 기술하는 HTTP, IMAP, SSH, TCP, UDP, IP 등의 프로토콜들이 있습니다.
이 관점에서 인터넷은 컴퓨터와 프로그램이 네트워크를 이루기 위해 어떻게 행동하는지 정한 양식의 집합입니다.
- 인터넷이 거대해지고 WiFi, 전자 상거래가 생기며 보안을 위해 SSL/TLS가 개발되었습니다.

`Domain 입력부터 화면이 나타날 때까지`{:.info}

**The process from the time you type in a website's URL to it finishing loading on your screen.**


- tcp stack


- What are HTTP methods? List all HTTP methods that you know, and explain them.


- HTTPS and SSL


- Traditionally, why has it been better to serve site assets from multiple domains?


- What is domain pre-fetching and how does it help with performance?



## System and OS


- Queue, heap, stack, data region of memory



- Difference between out of memory and stack overflow



- Context switching



- VM, page, swap



- Semaphore


- Thread, process


- Multithread, concurrent programming


- Difference between L1 and L2 cache


- deadlock, case and solution


- Other OS basics



# Languages

## OOP overall


`OOP basic`{:.info}

- OOP basic

`Class`{:.info}

- Class


- Inheritance, Multiple inheritance


- Override, overload

`Polymorphism`{:.info}

- Polymorphism




## Python


- OOP of Python, class, object, inheritance


- `Constructor`, `__self__`



- How hash table is implemented in Python



- Can class be used as a key of dictionary



- dictionary, mutable, immutable



- Special methods and dunder



- Difference between method and function


- Is `len()` is function? or method?



- Decorator



- Generator, iterator and their difference



- Abstract class



- Type casting



## HTML



- What does a `doctype` do?



- How do you serve a page with content in multiple languages?



- What kind of things must you be wary of when design or developing for multilingual sites?



- What are `data-` attributes good for?



- Consider HTML5 as an open web platform. What are the building blocks of HTML5?



- Describe the difference between a `cookie`, `sessionStorage` and `localStorage`.



- Describe the difference between `<script>`, `<script async>` and `<script defer>`.



- Why is it generally a good idea to position CSS `<link>`s between `<head></head>` and JS `<script>`s just before `</body>`? Do you know any exceptions?



- What is progressive rendering?



- Why you would use a `srcset` attribute in an image tag? Explain the process the browser uses when evaluating the content of this attribute.



- Have you used different HTML templating languages before?



## CSS



- What is CSS selector specificity and how does it work?



- What's the difference between "resetting" and "normalizing" CSS? Which would you choose, and why?



- Describe Floats and how they work.



- Describe z-index and how stacking context is formed.



- Describe BFC (Block Formatting Context) and how it works.



- What are the various clearing techniques and which is appropriate for what context?



- How would you approach fixing browser-specific styling issues?



- How do you serve your pages for feature-constrained browsers?
  
  -  What techniques/processes do you use?



- What are the different ways to visually hide content (and make it available only for screen readers)?



- Have you ever used a grid system, and if so, what do you prefer?



- Have you used or implemented media queries or mobile specific layouts/CSS?



- Are you familiar with styling SVG?



- Can you give an example of an `@media` property other than `screen`?



- What are some of the "gotchas" for writing efficient CSS?



- What are the advantages/disadvantages of using CSS preprocessors?
  
  - Describe what you like and dislike about the CSS preprocessors you have used.



- How would you implement a web design comp that uses non-standard fonts?



- Explain how a browser determines what elements match a CSS selector.



- Describe pseudo-elements and discuss what they are used for.



- Explain your understanding of the box model and how you would tell the browser in CSS to render your layout in different box models.



- What does `* { box-sizing: border-box; }` do? What are its advantages?



- What is the CSS `display` property and can you give a few examples of its use?



- What's the difference between inline and inline-block?



- What's the difference between the "nth-of-type()" and "nth-child()" selectors?



- What's the difference between a relative, fixed, absolute and statically positioned element?



- What existing CSS frameworks have you used locally, or in production? How would you change/improve them?



- Have you played around with the new CSS Flexbox or Grid specs?



- Can you explain the difference between coding a web site to be responsive versus using a mobile-first strategy?



- Have you ever worked with retina graphics? If so, when and what techniques did you use?



- Is there any reason you'd want to use `translate()` instead of absolute positioning, or vice-versa? And why?



## Javascript

- Explain event delegation.



- Explain how `this` works in JavaScript.



- Can you give an example of one of the ways that working with `this` has changed in ES6?



- Explain how prototypal inheritance works.



- What's the difference between a variable that is: `null`, `undefined` or `undeclared`?



- How would you go about checking for any of these states?



- What is a closure, and how/why would you use one?



- What language constructions do you use for iterating over object properties and array items?



- Can you describe the main difference between the `Array.forEach()` loop and `Array.map()` methods and why you would pick one versus the other?



- What's a typical use case for anonymous functions?



- What's the difference between host objects and native objects?



- Explain the difference between: `function Person(){}`, `var person = Person()`, and `var person = new Person()`?



- Explain the differences on the usage of `foo` between `function foo() {}` and `var foo = function() {}`



- Can you explain what `Function.call` and `Function.apply` do? What's the notable difference between the two?



- Explain `Function.prototype.bind`.



- What's the difference between feature detection, feature inference, and using the UA string?



- Explain "hoisting".



- Describe event bubbling.



- Describe event capturing.



- What's the difference between an "attribute" and a "property"?



- What are the pros and cons of extending built-in JavaScript objects?



- What is the difference between `==` and `===`?



- Explain the same-origin policy with regards to JavaScript.



- Why is it called a Ternary operator, what does the word "Ternary" indicate?



- What is strict mode? What are some of the advantages/disadvantages of using it?



- What are some of the advantages/disadvantages of writing JavaScript code in a language that compiles to JavaScript?



- What tools and techniques do you use debugging JavaScript code?



- Explain the difference between mutable and immutable objects.



- What is an example of an immutable object in JavaScript?



- What are the pros and cons of immutability?



- How can you achieve immutability in your own code?



- Explain the difference between synchronous and asynchronous functions.



- What is event loop?



- What is the difference between call stack and task queue?



- What are the differences between variables created using `let`, `var` or `const`?



- What are the differences between **ES6** class and **ES5** function constructors?



- Can you offer a use case for the new arrow `=>` function syntax? How does this new syntax differ from other functions?



- What advantage is there for using the arrow syntax for a method in a constructor?



- What is the definition of a higher-order function?



- Can you give an example for destructuring an object or an array?



- Can you give an example of generating a string with ES6 Template Literals?



- Can you give an example of a curry function and why this syntax offers an advantage?



- What are the benefits of using `spread syntax` and how is it different from `rest syntax`?



- How can you share code between files?



- Why you might want to create static class members?

## Coding questions

- Make this work:

  - `duplicate([1,2,3,4,5]); // [1,2,3,4,5,1,2,3,4,5]`


- Create a for loop that iterates up to `100` while outputting **"fizz"** at multiples of `3`, **"buzz"** at multiples of `5` and **"fizzbuzz"** at multiples of `3` and `5`



- What is the value of `foo`?

```javascript
var foo = 10 + '20';
```


- What will be the output of the code below?

```javascript
console.log(0.1 + 0.2 == 0.3);
```


- How would you make this work?

```javascript
add(2, 5); // 7
add(2)(5); // 7
```


- What value is returned from the following statement?

```javascript
"i'm a lasagna hog".split("").reverse().join("");
```


- What is the value of `window.foo`?

```javascript
( window.foo || ( window.foo = "bar" ) );
```


- What is the outcome of the two alerts below?

```javascript
var foo = "Hello";
(function() {
  var bar = " World";
  alert(foo + bar);
})();
alert(foo + bar);
```


- What is the value of `foo.length`?

```javascript
var foo = [];
foo.push(1);
foo.push(2);
```


- What is the value of `foo.x`?

```javascript
var foo = {n: 1};
var bar = foo;
foo.x = foo = {n: 2};
```



- What does the following code print?

```javascript
console.log('one');
setTimeout(function() {
  console.log('two');
}, 0);
Promise.resolve().then(function() {
  console.log('three');
})
console.log('four');
```


- What is the difference between these four promises?

```javascript
doSomething().then(function () {
  return doSomethingElse();
});

doSomething().then(function () {
  doSomethingElse();
});

doSomething().then(doSomethingElse());

doSomething().then(doSomethingElse);
```



# ETC

- A-star Algorithm


# 참고

- [h5bp's Github](https://github.com/h5bp/Front-end-Developer-Interview-Questions)

- [keon1.me](https://keon1.me/dev/2019/01/05/interview.html)

- https://medium.com/@User3141592/how-does-the-internet-work-edc2e22e7eb8

